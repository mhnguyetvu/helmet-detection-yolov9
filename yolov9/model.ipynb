{
 "cells": [
  {
<<<<<<< HEAD
=======
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ultralytics\n",
      "  Downloading ultralytics-8.3.74-py3-none-any.whl.metadata (35 kB)\n",
      "Requirement already satisfied: numpy<=2.1.1,>=1.23.0 in /Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages (from ultralytics) (1.26.4)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages (from ultralytics) (3.8.4)\n",
      "Collecting opencv-python>=4.6.0 (from ultralytics)\n",
      "  Downloading opencv_python-4.11.0.86-cp37-abi3-macosx_13_0_arm64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: pillow>=7.1.2 in /Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages (from ultralytics) (10.3.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages (from ultralytics) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.23.0 in /Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages (from ultralytics) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages (from ultralytics) (1.12.0)\n",
      "Requirement already satisfied: torch>=1.8.0 in /Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages (from ultralytics) (2.2.0)\n",
      "Collecting torchvision>=0.9.0 (from ultralytics)\n",
      "  Downloading torchvision-0.21.0-cp39-cp39-macosx_11_0_arm64.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages (from ultralytics) (4.66.5)\n",
      "Requirement already satisfied: psutil in /Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages (from ultralytics) (5.9.8)\n",
      "Collecting py-cpuinfo (from ultralytics)\n",
      "  Using cached py_cpuinfo-9.0.0-py3-none-any.whl.metadata (794 bytes)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages (from ultralytics) (2.2.0)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in /Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages (from ultralytics) (0.13.2)\n",
      "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
      "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages (from matplotlib>=3.3.0->ultralytics) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages (from matplotlib>=3.3.0->ultralytics) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages (from matplotlib>=3.3.0->ultralytics) (23.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages (from matplotlib>=3.3.0->ultralytics) (6.4.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages (from requests>=2.23.0->ultralytics) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages (from requests>=2.23.0->ultralytics) (2024.6.2)\n",
      "Requirement already satisfied: filelock in /Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
      "Requirement already satisfied: sympy in /Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics) (1.13.3)\n",
      "Requirement already satisfied: networkx in /Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics) (2024.9.0)\n",
      "Collecting torch>=1.8.0 (from ultralytics)\n",
      "  Downloading torch-2.6.0-cp39-none-macosx_11_0_arm64.whl.metadata (28 kB)\n",
      "Collecting sympy==1.13.1 (from torch>=1.8.0->ultralytics)\n",
      "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib>=3.3.0->ultralytics) (3.17.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n",
      "Downloading ultralytics-8.3.74-py3-none-any.whl (914 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m914.7/914.7 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading opencv_python-4.11.0.86-cp37-abi3-macosx_13_0_arm64.whl (37.3 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m37.3/37.3 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading torchvision-0.21.0-cp39-cp39-macosx_11_0_arm64.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.6.0-cp39-none-macosx_11_0_arm64.whl (66.5 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m66.5/66.5 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
      "Using cached py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
      "Installing collected packages: py-cpuinfo, sympy, opencv-python, torch, ultralytics-thop, torchvision, ultralytics\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.13.3\n",
      "    Uninstalling sympy-1.13.3:\n",
      "      Successfully uninstalled sympy-1.13.3\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.2.0\n",
      "    Uninstalling torch-2.2.0:\n",
      "      Successfully uninstalled torch-2.2.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchtext 0.17.0 requires torch==2.2.0, but you have torch 2.6.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed opencv-python-4.11.0.86 py-cpuinfo-9.0.0 sympy-1.13.1 torch-2.6.0 torchvision-0.21.0 ultralytics-8.3.74 ultralytics-thop-2.0.14\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'yolov9'...\n",
      "remote: Enumerating objects: 781, done.\u001b[K\n",
      "remote: Total 781 (delta 0), reused 0 (delta 0), pack-reused 781 (from 1)\u001b[K\n",
      "Receiving objects: 100% (781/781), 3.27 MiB | 3.44 MiB/s, done.\n",
      "Resolving deltas: 100% (331/331), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/WongKinYiu/yolov9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-02-12 20:13:01--  https://github.com/WongKinYiu/yolov9/releases/download/v0.1/yolov9-e.pt\n",
      "Resolving github.com (github.com)... 20.205.243.166\n",
      "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/759338070/1380cea0-94b4-4d8b-adab-773e081eacee?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250212%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250212T131301Z&X-Amz-Expires=300&X-Amz-Signature=1d0148d1c78022d3dd158872e729dd461c7dc353ee133ddfe8995fbd8c5fab7e&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dyolov9-e.pt&response-content-type=application%2Foctet-stream [following]\n",
      "--2025-02-12 20:13:01--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/759338070/1380cea0-94b4-4d8b-adab-773e081eacee?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250212%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250212T131301Z&X-Amz-Expires=300&X-Amz-Signature=1d0148d1c78022d3dd158872e729dd461c7dc353ee133ddfe8995fbd8c5fab7e&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dyolov9-e.pt&response-content-type=application%2Foctet-stream\n",
      "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.111.133, ...\n",
      "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 140217688 (134M) [application/octet-stream]\n",
      "Saving to: â€˜/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.ptâ€™\n",
      "\n",
      "yolov9-e.pt         100%[===================>] 133.72M  4.28MB/s    in 32s     \n",
      "\n",
      "2025-02-12 20:13:33 (4.24 MB/s) - â€˜/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.ptâ€™ saved [140217688/140217688]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## download weights pretrain \n",
    "!wget -P /Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9 https://github.com/WongKinYiu/yolov9/releases/download/v0.1/yolov9-e.pt\n"
   ]
  },
  {
>>>>>>> 6f9154c (Add code)
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test with YOLOv9 pretrained model\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 7,
>>>>>>> 6f9154c (Add code)
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
<<<<<<< HEAD
=======
    "from ultralytics import YOLO\n",
>>>>>>> 6f9154c (Add code)
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = '/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of images: 764\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "764"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_images(directory):\n",
    "    \"\"\"Count the number of images in the given directory.\"\"\"\n",
    "    image_files = [f for f in os.listdir(directory) if f.endswith(('png', 'jpg', 'jpeg'))]\n",
    "    print(f\"Total number of images: {len(image_files)}\")\n",
    "    return len(image_files)\n",
    "\n",
    "# Count images in the directory\n",
    "count_images(directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets229.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets229.png: 448x640 1 person, 1 motorcycle, 448x640 1 person, 1 motorcycle, 836.9ms\n",
      "Speed: 3.2ms pre-process, 418.5ms inference, 4.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp10\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets567.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets567.png: 480x640 5 persons, 5 cars, 4 motorcycles, 480x640 6 persons, 4 cars, 4 motorcycles, 982.9ms\n",
      "Speed: 0.4ms pre-process, 491.5ms inference, 1.1ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp11\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets201.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets201.png: 512x640 1 person, 1 motorcycle, 1 truck, 512x640 1 person, 1 motorcycle, 2 trucks, 1141.6ms\n",
      "Speed: 2.2ms pre-process, 570.8ms inference, 2.4ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp12\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets215.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets215.png: 448x640 11 persons, 6 motorcycles, 448x640 12 persons, 6 motorcycles, 964.7ms\n",
      "Speed: 0.6ms pre-process, 482.3ms inference, 2.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp13\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets573.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets573.png: 448x640 3 persons, 2 bicycles, 1 car, 2 trucks, 448x640 3 persons, 2 bicycles, 1 truck, 753.0ms\n",
      "Speed: 0.5ms pre-process, 376.5ms inference, 3.4ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp14\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets598.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets598.png: 448x640 1 person, 1 bicycle, 1 backpack, 448x640 1 person, 1 bicycle, 1 backpack, 761.1ms\n",
      "Speed: 0.4ms pre-process, 380.6ms inference, 1.1ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp15\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets17.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets17.png: 384x640 2 persons, 2 bicycles, 3 bottles, 384x640 2 persons, 2 bicycles, 2 bottles, 590.3ms\n",
      "Speed: 0.3ms pre-process, 295.1ms inference, 0.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp16\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets759.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets759.png: 448x640 4 persons, 1 car, 4 motorcycles, 448x640 4 persons, 1 car, 4 motorcycles, 720.2ms\n",
      "Speed: 0.3ms pre-process, 360.1ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp17\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets765.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets765.png: 384x640 1 person, 1 bicycle, 1 motorcycle, 384x640 1 person, 1 bicycle, 654.3ms\n",
      "Speed: 0.4ms pre-process, 327.1ms inference, 1.0ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp18\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets639.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets639.png: 448x640 3 persons, 2 motorcycles, 448x640 2 persons, 4 motorcycles, 652.5ms\n",
      "Speed: 0.4ms pre-process, 326.2ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp19\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets177.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets177.png: 448x640 1 person, 1 bicycle, 1 bottle, 448x640 1 person, 1 bicycle, 1 bottle, 623.1ms\n",
      "Speed: 0.4ms pre-process, 311.5ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp20\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets611.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets611.png: 416x640 3 persons, 3 bicycles, 416x640 3 persons, 3 bicycles, 579.0ms\n",
      "Speed: 0.4ms pre-process, 289.5ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp21\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets605.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets605.png: 480x640 6 persons, 1 motorcycle, 1 backpack, 480x640 7 persons, 2 motorcycles, 1 backpack, 715.0ms\n",
      "Speed: 0.4ms pre-process, 357.5ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp22\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets163.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets163.png: 448x640 5 persons, 5 bicycles, 448x640 5 persons, 5 bicycles, 652.1ms\n",
      "Speed: 0.1ms pre-process, 326.1ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp23\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets188.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets188.png: 448x640 1 person, 1 bicycle, 2 backpacks, 448x640 1 person, 1 bicycle, 2 backpacks, 688.6ms\n",
      "Speed: 0.4ms pre-process, 344.3ms inference, 0.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp24\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets349.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets349.png: 608x640 6 persons, 1 motorcycle, 608x640 7 persons, 1 car, 1 motorcycle, 805.0ms\n",
      "Speed: 0.5ms pre-process, 402.5ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp25\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets413.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets413.png: 384x640 2 persons, 1 motorcycle, 384x640 2 persons, 1 motorcycle, 536.3ms\n",
      "Speed: 0.3ms pre-process, 268.1ms inference, 0.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp26\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets375.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets375.png: 352x640 14 persons, 1 car, 7 motorcycles, 2 handbags, 352x640 13 persons, 1 car, 8 motorcycles, 2 handbags, 491.6ms\n",
      "Speed: 0.3ms pre-process, 245.8ms inference, 1.0ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp27\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets361.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets361.png: 448x640 4 persons, 1 handbag, 1 skateboard, 448x640 3 persons, 1 bicycle, 1 skateboard, 673.1ms\n",
      "Speed: 0.4ms pre-process, 336.6ms inference, 0.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp28\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets407.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets407.png: 384x640 1 person, 1 motorcycle, 384x640 1 person, 1 motorcycle, 634.0ms\n",
      "Speed: 0.4ms pre-process, 317.0ms inference, 1.1ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp29\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets360.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets360.png: 448x640 3 persons, 1 bicycle, 448x640 3 persons, 1 bicycle, 1 sports ball, 710.9ms\n",
      "Speed: 0.4ms pre-process, 355.5ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp30\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets406.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets406.png: 640x640 1 person, 1 bicycle, 1 motorcycle, 640x640 1 person, 1 bicycle, 952.9ms\n",
      "Speed: 0.5ms pre-process, 476.4ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp31\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets412.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets412.png: 640x640 1 person, 1 car, 2 motorcycles, 2 trucks, 640x640 1 person, 1 car, 2 motorcycles, 1 truck, 847.2ms\n",
      "Speed: 0.6ms pre-process, 423.6ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp32\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets374.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets374.png: 512x640 1 person, 512x640 1 person, 1 bicycle, 757.8ms\n",
      "Speed: 0.5ms pre-process, 378.9ms inference, 0.9ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp33\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets348.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets348.png: 448x640 1 person, 1 bicycle, 448x640 1 person, 1 bicycle, 615.5ms\n",
      "Speed: 0.5ms pre-process, 307.8ms inference, 2.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp34\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets189.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets189.png: 640x448 3 persons, 1 motorcycle, 640x448 3 persons, 1 car, 1 motorcycle, 666.7ms\n",
      "Speed: 0.3ms pre-process, 333.4ms inference, 0.9ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp35\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets604.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets604.png: 448x640 4 persons, 1 motorcycle, 448x640 4 persons, 1 motorcycle, 644.9ms\n",
      "Speed: 0.4ms pre-process, 322.4ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp36\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets162.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets162.png: 640x448 2 persons, 2 bicycles, 640x448 2 persons, 2 bicycles, 645.3ms\n",
      "Speed: 0.4ms pre-process, 322.6ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp37\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets176.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets176.png: 448x640 10 persons, 5 bicycles, 1 train, 2 backpacks, 448x640 9 persons, 7 bicycles, 3 backpacks, 2 handbags, 624.9ms\n",
      "Speed: 0.5ms pre-process, 312.4ms inference, 0.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp38\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets610.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets610.png: 640x512 2 persons, 2 bicycles, 640x512 2 persons, 2 bicycles, 781.4ms\n",
      "Speed: 0.5ms pre-process, 390.7ms inference, 0.9ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp39\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets638.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets638.png: 640x512 6 persons, 1 motorcycle, 640x512 9 persons, 1 motorcycle, 766.7ms\n",
      "Speed: 0.4ms pre-process, 383.3ms inference, 2.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp40\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets764.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets764.png: 640x640 5 persons, 1 motorcycle, 1 umbrella, 640x640 6 persons, 1 motorcycle, 1 umbrella, 977.1ms\n",
      "Speed: 0.6ms pre-process, 488.5ms inference, 1.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp41\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets758.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets758.png: 480x640 2 persons, 3 bicycles, 2 bottles, 480x640 2 persons, 2 bicycles, 1 bench, 2 bottles, 672.3ms\n",
      "Speed: 0.4ms pre-process, 336.2ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp42\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets16.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets16.png: 448x640 7 persons, 5 bicycles, 448x640 7 persons, 5 bicycles, 620.1ms\n",
      "Speed: 0.4ms pre-process, 310.1ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp43\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets599.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets599.png: 512x640 4 persons, 4 bicycles, 4 cars, 1 bus, 2 backpacks, 512x640 5 persons, 4 bicycles, 4 cars, 1 bus, 2 backpacks, 773.3ms\n",
      "Speed: 0.4ms pre-process, 386.6ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp44\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets214.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets214.png: 480x640 1 person, 1 bicycle, 480x640 1 person, 1 bicycle, 713.2ms\n",
      "Speed: 0.5ms pre-process, 356.6ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp45\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets572.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets572.png: 416x640 5 persons, 5 motorcycles, 416x640 5 persons, 5 motorcycles, 625.3ms\n",
      "Speed: 0.3ms pre-process, 312.7ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp46\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets566.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets566.png: 384x640 1 person, 2 bicycles, 1 car, 384x640 1 person, 2 bicycles, 1 car, 522.8ms\n",
      "Speed: 0.7ms pre-process, 261.4ms inference, 1.2ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp47\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets200.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets200.png: 480x640 4 persons, 2 cars, 4 motorcycles, 1 truck, 1 backpack, 480x640 5 persons, 3 cars, 3 motorcycles, 1 truck, 1 backpack, 715.5ms\n",
      "Speed: 0.4ms pre-process, 357.8ms inference, 2.3ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp48\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets228.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets228.png: 512x640 7 persons, 3 cars, 6 motorcycles, 512x640 8 persons, 3 cars, 6 motorcycles, 1452.9ms\n",
      "Speed: 0.4ms pre-process, 726.5ms inference, 2.1ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp49\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets558.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets558.png: 480x640 4 persons, 1 motorcycle, 1 handbag, 480x640 4 persons, 1 motorcycle, 1 backpack, 1 handbag, 923.4ms\n",
      "Speed: 0.4ms pre-process, 461.7ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp50\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets570.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets570.png: 480x640 1 person, 1 motorcycle, 2 trucks, 480x640 3 persons, 1 motorcycle, 2 trucks, 971.5ms\n",
      "Speed: 0.2ms pre-process, 485.7ms inference, 1.4ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp51\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets216.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets216.png: 352x640 2 persons, 1 bicycle, 1 motorcycle, 1 truck, 1 dog, 1 chair, 352x640 2 persons, 2 bicycles, 1 motorcycle, 1 truck, 730.6ms\n",
      "Speed: 0.4ms pre-process, 365.3ms inference, 1.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp52\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets202.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets202.png: 480x640 2 persons, 2 motorcycles, 480x640 2 persons, 2 motorcycles, 1045.9ms\n",
      "Speed: 0.4ms pre-process, 522.9ms inference, 1.0ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp53\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets564.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets564.png: 640x640 1 person, 1 bicycle, 2 cars, 2 benchs, 640x640 1 person, 1 bicycle, 2 cars, 1 bench, 1084.1ms\n",
      "Speed: 0.6ms pre-process, 542.0ms inference, 1.1ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp54\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets28.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets28.png: 416x640 2 persons, 1 motorcycle, 416x640 2 persons, 1 motorcycle, 748.6ms\n",
      "Speed: 0.5ms pre-process, 374.3ms inference, 1.2ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp55\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets14.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets14.png: 384x640 4 persons, 1 car, 1 motorcycle, 384x640 5 persons, 2 cars, 1 motorcycle, 752.5ms\n",
      "Speed: 0.6ms pre-process, 376.2ms inference, 3.0ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp56\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets148.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets148.png: 640x640 2 persons, 2 bicycles, 2 bottles, 640x640 2 persons, 2 bicycles, 2 bottles, 1043.3ms\n",
      "Speed: 0.4ms pre-process, 521.7ms inference, 0.9ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp57\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets160.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets160.png: 448x640 3 persons, 2 bicycles, 1 car, 1 handbag, 448x640 3 persons, 2 bicycles, 1 car, 1 stop sign, 1 handbag, 841.7ms\n",
      "Speed: 0.4ms pre-process, 420.8ms inference, 2.9ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp58\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets606.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets606.png: 576x640 3 persons, 1 motorcycle, 576x640 3 persons, 1 motorcycle, 981.9ms\n",
      "Speed: 0.7ms pre-process, 491.0ms inference, 3.5ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp59\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets612.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets612.png: 480x640 1 person, 3 motorcycles, 480x640 1 person, 3 motorcycles, 1059.9ms\n",
      "Speed: 0.4ms pre-process, 530.0ms inference, 0.9ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp60\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets174.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets174.png: 448x640 2 persons, 2 bicycles, 1 backpack, 448x640 2 persons, 2 bicycles, 2 backpacks, 969.7ms\n",
      "Speed: 2.0ms pre-process, 484.9ms inference, 1.5ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp61\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets438.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets438.png: 480x640 1 person, 1 motorcycle, 480x640 1 person, 1 motorcycle, 1 backpack, 1081.1ms\n",
      "Speed: 0.3ms pre-process, 540.6ms inference, 2.1ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp62\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets404.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets404.png: 384x640 3 persons, 1 motorcycle, 1 dog, 384x640 3 persons, 1 motorcycle, 1 dog, 1065.9ms\n",
      "Speed: 1.3ms pre-process, 533.0ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp63\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets362.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets362.png: 384x640 3 persons, 11 cars, 2 motorcycles, 384x640 1 person, 11 cars, 2 motorcycles, 909.3ms\n",
      "Speed: 2.4ms pre-process, 454.7ms inference, 3.3ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp64\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets376.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets376.png: 480x640 5 persons, 2 cars, 2 motorcycles, 2 trucks, 1 cow, 480x640 6 persons, 2 cars, 2 motorcycles, 1 truck, 1 dog, 1 cow, 981.3ms\n",
      "Speed: 3.7ms pre-process, 490.6ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp65\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets410.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets410.png: 384x640 4 persons, 1 car, 1 motorcycle, 384x640 5 persons, 2 cars, 1 motorcycle, 758.5ms\n",
      "Speed: 0.4ms pre-process, 379.3ms inference, 1.0ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp66\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets389.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets389.png: 384x640 3 persons, 3 cars, 1 motorcycle, 384x640 3 persons, 2 cars, 1 motorcycle, 756.2ms\n",
      "Speed: 0.3ms pre-process, 378.1ms inference, 1.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp67\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets388.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets388.png: 512x640 1 person, 1 bicycle, 512x640 1 person, 1 bicycle, 1135.9ms\n",
      "Speed: 0.4ms pre-process, 568.0ms inference, 5.5ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp68\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets377.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets377.png: 448x640 11 persons, 7 bicycles, 448x640 11 persons, 7 bicycles, 2 handbags, 840.4ms\n",
      "Speed: 0.4ms pre-process, 420.2ms inference, 2.3ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp69\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets411.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets411.png: 384x640 4 persons, 2 cars, 5 motorcycles, 384x640 4 persons, 4 cars, 4 motorcycles, 696.0ms\n",
      "Speed: 0.8ms pre-process, 348.0ms inference, 0.9ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp70\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets405.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets405.png: 256x640 2 persons, 2 motorcycles, 256x640 2 persons, 2 motorcycles, 428.7ms\n",
      "Speed: 0.3ms pre-process, 214.3ms inference, 0.9ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp71\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets363.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets363.png: 448x640 1 person, 1 bicycle, 448x640 1 person, 1 bicycle, 683.0ms\n",
      "Speed: 0.6ms pre-process, 341.5ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp72\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets439.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets439.png: 352x640 10 persons, 9 bicycles, 4 cars, 1 truck, 352x640 10 persons, 9 bicycles, 3 cars, 2 trucks, 816.7ms\n",
      "Speed: 0.3ms pre-process, 408.4ms inference, 1.3ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp73\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets613.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets613.png: 416x640 6 persons, 4 motorcycles, 1 backpack, 416x640 10 persons, 4 motorcycles, 1 backpack, 1 cell phone, 789.7ms\n",
      "Speed: 0.4ms pre-process, 394.9ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp74\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets175.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets175.png: 480x640 6 persons, 1 bicycle, 2 motorcycles, 1 truck, 480x640 8 persons, 1 bicycle, 1 car, 3 motorcycles, 707.3ms\n",
      "Speed: 0.4ms pre-process, 353.7ms inference, 1.0ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp75\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets161.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets161.png: 512x640 1 person, 1 bicycle, 512x640 1 person, 1 bicycle, 809.3ms\n",
      "Speed: 0.5ms pre-process, 404.6ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp76\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets607.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets607.png: 448x640 1 person, 1 motorcycle, 448x640 1 person, 1 motorcycle, 658.8ms\n",
      "Speed: 0.5ms pre-process, 329.4ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp77\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets149.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets149.png: 480x640 2 persons, 3 bicycles, 3 backpacks, 480x640 3 persons, 2 bicycles, 2 backpacks, 1 handbag, 720.7ms\n",
      "Speed: 0.4ms pre-process, 360.4ms inference, 0.9ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp78\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets15.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets15.png: 448x640 2 persons, 2 cars, 448x640 2 persons, 2 cars, 1 motorcycle, 668.3ms\n",
      "Speed: 0.3ms pre-process, 334.2ms inference, 1.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp79\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets29.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets29.png: 448x640 3 persons, 2 motorcycles, 448x640 2 persons, 3 motorcycles, 701.0ms\n",
      "Speed: 0.5ms pre-process, 350.5ms inference, 1.0ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp80\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets203.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets203.png: 448x640 9 persons, 10 motorcycles, 448x640 9 persons, 12 motorcycles, 650.7ms\n",
      "Speed: 0.4ms pre-process, 325.4ms inference, 0.9ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp81\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets565.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets565.png: 448x640 2 persons, 1 bicycle, 2 bottles, 448x640 2 persons, 1 bicycle, 2 bottles, 670.9ms\n",
      "Speed: 0.4ms pre-process, 335.5ms inference, 1.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp82\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets571.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets571.png: 640x640 6 persons, 5 cars, 6 motorcycles, 2 trucks, 2 traffic lights, 640x640 5 persons, 5 cars, 6 motorcycles, 2 trucks, 1 traffic light, 919.6ms\n",
      "Speed: 0.6ms pre-process, 459.8ms inference, 1.2ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp83\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets217.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets217.png: 448x640 7 persons, 8 cars, 2 motorcycles, 2 trucks, 448x640 8 persons, 7 cars, 2 motorcycles, 1 truck, 1 cell phone, 661.9ms\n",
      "Speed: 0.4ms pre-process, 331.0ms inference, 1.0ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp84\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets559.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets559.png: 416x640 5 persons, 2 motorcycles, 416x640 5 persons, 2 motorcycles, 660.8ms\n",
      "Speed: 0.4ms pre-process, 330.4ms inference, 1.0ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp85\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets213.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets213.png: 512x640 4 persons, 4 bicycles, 4 cars, 1 bus, 2 backpacks, 512x640 5 persons, 4 bicycles, 4 cars, 1 bus, 2 backpacks, 797.7ms\n",
      "Speed: 0.4ms pre-process, 398.8ms inference, 0.9ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp86\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets575.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets575.png: 640x480 4 persons, 3 cars, 1 motorcycle, 640x480 4 persons, 3 cars, 1 motorcycle, 729.0ms\n",
      "Speed: 0.5ms pre-process, 364.5ms inference, 0.9ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp87\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets561.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets561.png: 480x640 3 persons, 1 motorcycle, 480x640 3 persons, 1 motorcycle, 724.5ms\n",
      "Speed: 0.5ms pre-process, 362.3ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp88\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets207.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets207.png: 544x640 2 persons, 2 bicycles, 544x640 2 persons, 2 bicycles, 859.9ms\n",
      "Speed: 0.5ms pre-process, 430.0ms inference, 2.9ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp89\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets549.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets549.png: 448x640 1 person, 1 car, 1 motorcycle, 448x640 1 person, 1 car, 1 motorcycle, 654.5ms\n",
      "Speed: 0.4ms pre-process, 327.3ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp90\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets11.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets11.png: 480x640 6 persons, 5 motorcycles, 480x640 10 persons, 5 motorcycles, 1 backpack, 677.8ms\n",
      "Speed: 0.5ms pre-process, 338.9ms inference, 0.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp91\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets39.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets39.png: 416x640 3 persons, 2 motorcycles, 1 truck, 416x640 4 persons, 2 motorcycles, 1 truck, 643.1ms\n",
      "Speed: 0.6ms pre-process, 321.6ms inference, 0.9ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp92\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets763.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets763.png: 448x640 7 persons, 5 bicycles, 448x640 7 persons, 5 bicycles, 649.6ms\n",
      "Speed: 0.3ms pre-process, 324.8ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp93\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets9.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets9.png: 384x640 3 persons, 1 bicycle, 2 cars, 384x640 3 persons, 1 bicycle, 2 cars, 1 handbag, 560.0ms\n",
      "Speed: 0.5ms pre-process, 280.0ms inference, 0.9ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp94\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets603.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets603.png: 448x640 5 persons, 1 bicycle, 1 car, 2 motorcycles, 448x640 6 persons, 1 bicycle, 1 car, 2 motorcycles, 683.6ms\n",
      "Speed: 0.4ms pre-process, 341.8ms inference, 2.9ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp95\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets165.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets165.png: 384x640 2 persons, 1 motorcycle, 384x640 1 person, 1 motorcycle, 594.9ms\n",
      "Speed: 0.1ms pre-process, 297.5ms inference, 0.9ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp96\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets171.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets171.png: 352x640 12 persons, 9 bicycles, 1 backpack, 352x640 13 persons, 11 bicycles, 1 backpack, 722.4ms\n",
      "Speed: 2.6ms pre-process, 361.2ms inference, 1.2ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp97\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets617.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets617.png: 448x640 3 persons, 2 bicycles, 448x640 3 persons, 2 bicycles, 681.9ms\n",
      "Speed: 0.4ms pre-process, 341.0ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp98\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets159.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets159.png: 448x640 2 persons, 2 skateboards, 448x640 2 persons, 2 skateboards, 647.4ms\n",
      "Speed: 0.9ms pre-process, 323.7ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp99\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets367.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets367.png: 512x640 2 persons, 4 cars, 1 motorcycle, 512x640 2 persons, 4 cars, 1 motorcycle, 921.7ms\n",
      "Speed: 0.4ms pre-process, 460.9ms inference, 1.2ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp100\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets401.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets401.png: 480x640 1 person, 10 motorcycles, 1 toilet, 480x640 2 persons, 10 motorcycles, 768.3ms\n",
      "Speed: 0.4ms pre-process, 384.1ms inference, 0.9ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp101\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets415.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets415.png: 448x640 3 persons, 3 bicycles, 1 backpack, 448x640 3 persons, 3 bicycles, 3 backpacks, 642.7ms\n",
      "Speed: 0.5ms pre-process, 321.3ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp102\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets373.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets373.png: 448x640 2 persons, 1 bicycle, 1 bottle, 448x640 2 persons, 1 bicycle, 1 bottle, 610.7ms\n",
      "Speed: 0.2ms pre-process, 305.3ms inference, 0.9ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp103\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets429.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets429.png: 448x640 2 persons, 1 bicycle, 448x640 2 persons, 1 bicycle, 658.7ms\n",
      "Speed: 0.5ms pre-process, 329.4ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp104\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets398.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets398.png: 384x640 8 persons, 5 motorcycles, 2 backpacks, 384x640 7 persons, 6 motorcycles, 2 backpacks, 569.8ms\n",
      "Speed: 0.4ms pre-process, 284.9ms inference, 0.9ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp105\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets399.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets399.png: 448x640 11 persons, 10 bicycles, 3 cars, 3 traffic lights, 1 backpack, 448x640 11 persons, 9 bicycles, 4 cars, 3 traffic lights, 4 backpacks, 687.2ms\n",
      "Speed: 0.1ms pre-process, 343.6ms inference, 2.4ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp106\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets428.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets428.png: 640x480 3 persons, 640x480 2 persons, 1 motorcycle, 785.4ms\n",
      "Speed: 0.5ms pre-process, 392.7ms inference, 0.9ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp107\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets414.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets414.png: 384x640 4 persons, 1 bicycle, 1 car, 1 motorcycle, 384x640 4 persons, 2 bicycles, 2 cars, 2 motorcycles, 1302.5ms\n",
      "Speed: 0.3ms pre-process, 651.3ms inference, 1.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp108\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets372.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets372.png: 448x640 3 persons, 2 motorcycles, 448x640 3 persons, 2 motorcycles, 834.0ms\n",
      "Speed: 0.5ms pre-process, 417.0ms inference, 0.9ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp109\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets366.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets366.png: 384x640 3 persons, 1 car, 1 motorcycle, 1 truck, 384x640 3 persons, 1 car, 1 motorcycle, 1 truck, 592.9ms\n",
      "Speed: 0.4ms pre-process, 296.4ms inference, 0.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp110\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets400.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets400.png: 640x640 1 person, 1 bicycle, 640x640 1 person, 1 bicycle, 951.3ms\n",
      "Speed: 1.3ms pre-process, 475.7ms inference, 1.3ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp111\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets158.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets158.png: 448x640 1 person, 1 motorcycle, 448x640 1 person, 1 motorcycle, 604.6ms\n",
      "Speed: 0.4ms pre-process, 302.3ms inference, 0.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp112\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets170.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets170.png: 448x640 1 person, 1 motorcycle, 2 potted plants, 448x640 1 person, 1 motorcycle, 3 potted plants, 661.6ms\n",
      "Speed: 0.4ms pre-process, 330.8ms inference, 0.9ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp113\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets616.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets616.png: 448x640 4 persons, 2 bicycles, 1 skateboard, 448x640 4 persons, 2 bicycles, 667.9ms\n",
      "Speed: 0.4ms pre-process, 333.9ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp114\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets602.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets602.png: 384x640 1 person, 1 motorcycle, 384x640 1 person, 1 motorcycle, 591.3ms\n",
      "Speed: 0.4ms pre-process, 295.7ms inference, 1.0ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp115\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets164.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets164.png: 448x640 10 persons, 9 bicycles, 1 backpack, 448x640 10 persons, 9 bicycles, 1 backpack, 634.1ms\n",
      "Speed: 0.4ms pre-process, 317.1ms inference, 1.5ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp116\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets8.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets8.png: 480x640 4 persons, 1 motorcycle, 480x640 4 persons, 1 motorcycle, 1 backpack, 1 handbag, 698.0ms\n",
      "Speed: 0.5ms pre-process, 349.0ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp117\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets762.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets762.png: 608x640 1 person, 1 car, 1 motorcycle, 608x640 1 person, 1 car, 1 motorcycle, 865.0ms\n",
      "Speed: 0.6ms pre-process, 432.5ms inference, 1.0ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp118\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets38.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets38.png: 448x640 2 persons, 2 bicycles, 1 car, 448x640 2 persons, 2 bicycles, 1 car, 1 backpack, 686.4ms\n",
      "Speed: 0.4ms pre-process, 343.2ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp119\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets10.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets10.png: 416x640 3 persons, 2 cars, 1 motorcycle, 1 bus, 1 truck, 1 backpack, 416x640 3 persons, 4 cars, 1 motorcycle, 1 truck, 1 backpack, 611.0ms\n",
      "Speed: 0.4ms pre-process, 305.5ms inference, 0.9ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp120\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets548.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets548.png: 448x640 2 persons, 1 motorcycle, 448x640 2 persons, 1 motorcycle, 679.2ms\n",
      "Speed: 0.4ms pre-process, 339.6ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp121\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets560.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets560.png: 640x544 5 persons, 4 motorcycles, 1 traffic light, 640x544 6 persons, 4 motorcycles, 1 traffic light, 774.4ms\n",
      "Speed: 0.4ms pre-process, 387.2ms inference, 1.2ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp122\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets206.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets206.png: 640x448 1 person, 1 baseball bat, 640x448 1 person, 1 baseball bat, 626.8ms\n",
      "Speed: 0.3ms pre-process, 313.4ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp123\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets212.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets212.png: 448x640 1 person, 1 motorcycle, 2 potted plants, 448x640 1 person, 1 motorcycle, 3 potted plants, 710.7ms\n",
      "Speed: 1.2ms pre-process, 355.4ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp124\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets574.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets574.png: 448x640 10 persons, 9 bicycles, 1 backpack, 448x640 10 persons, 9 bicycles, 1 backpack, 642.7ms\n",
      "Speed: 0.4ms pre-process, 321.3ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp125\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets204.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets204.png: 480x640 10 persons, 9 bicycles, 2 cars, 1 traffic light, 480x640 11 persons, 9 bicycles, 4 cars, 2 buss, 2 traffic lights, 1 backpack, 2 potted plants, 765.1ms\n",
      "Speed: 0.5ms pre-process, 382.6ms inference, 2.9ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp126\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets562.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets562.png: 640x384 2 persons, 1 car, 1 motorcycle, 640x384 3 persons, 2 cars, 1 motorcycle, 607.9ms\n",
      "Speed: 0.3ms pre-process, 303.9ms inference, 0.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp127\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets576.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets576.png: 640x448 1 person, 1 bicycle, 1 car, 640x448 1 person, 1 bicycle, 1 car, 692.5ms\n",
      "Speed: 0.6ms pre-process, 346.3ms inference, 4.2ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp128\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets210.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets210.png: 448x640 3 persons, 2 motorcycles, 448x640 2 persons, 1 car, 2 motorcycles, 1 bus, 682.1ms\n",
      "Speed: 0.4ms pre-process, 341.1ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp129\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets238.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets238.png: 352x640 1 person, 1 motorcycle, 2 kites, 352x640 1 person, 1 motorcycle, 524.4ms\n",
      "Speed: 0.4ms pre-process, 262.2ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp130\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets12.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets12.png: 480x640 12 persons, 480x640 11 persons, 897.3ms\n",
      "Speed: 0.3ms pre-process, 448.6ms inference, 0.9ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp131\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets589.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets589.png: 416x640 2 persons, 2 bicycles, 416x640 2 persons, 2 bicycles, 722.6ms\n",
      "Speed: 0.4ms pre-process, 361.3ms inference, 1.3ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp132\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets760.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets760.png: 448x640 11 persons, 1 car, 4 motorcycles, 448x640 10 persons, 1 car, 4 motorcycles, 1 backpack, 678.7ms\n",
      "Speed: 0.5ms pre-process, 339.3ms inference, 1.0ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp133\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets748.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets748.png: 448x640 1 person, 1 motorcycle, 448x640 1 person, 1 motorcycle, 701.8ms\n",
      "Speed: 0.4ms pre-process, 350.9ms inference, 1.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp134\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets614.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets614.png: 448x640 11 persons, 10 bicycles, 3 cars, 3 traffic lights, 1 backpack, 448x640 11 persons, 9 bicycles, 4 cars, 3 traffic lights, 4 backpacks, 663.5ms\n",
      "Speed: 0.4ms pre-process, 331.8ms inference, 0.9ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp135\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets172.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets172.png: 480x640 3 persons, 2 motorcycles, 480x640 3 persons, 3 motorcycles, 716.4ms\n",
      "Speed: 0.5ms pre-process, 358.2ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp136\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets166.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets166.png: 640x640 1 person, 1 bicycle, 1 handbag, 640x640 1 person, 1 bicycle, 1 handbag, 915.4ms\n",
      "Speed: 2.0ms pre-process, 457.7ms inference, 0.9ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp137\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets600.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets600.png: 416x640 8 persons, 2 bicycles, 1 motorcycle, 1 bus, 1 handbag, 416x640 7 persons, 1 bicycle, 1 motorcycle, 1 handbag, 650.7ms\n",
      "Speed: 0.5ms pre-process, 325.4ms inference, 0.9ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp138\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets628.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets628.png: 480x640 5 persons, 3 bicycles, 480x640 6 persons, 2 bicycles, 693.9ms\n",
      "Speed: 0.4ms pre-process, 347.0ms inference, 1.2ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp139\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets199.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets199.png: 384x640 2 persons, 1 motorcycle, 384x640 2 persons, 1 motorcycle, 586.1ms\n",
      "Speed: 0.3ms pre-process, 293.1ms inference, 1.2ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp140\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets370.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets370.png: 480x640 2 persons, 3 cars, 2 motorcycles, 1 truck, 480x640 2 persons, 2 cars, 1 motorcycle, 715.1ms\n",
      "Speed: 0.2ms pre-process, 357.6ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp141\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets416.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets416.png: 640x512 2 persons, 2 bicycles, 640x512 2 persons, 2 bicycles, 792.9ms\n",
      "Speed: 0.2ms pre-process, 396.5ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp142\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets402.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets402.png: 384x640 3 persons, 2 cars, 2 motorcycles, 1 truck, 384x640 3 persons, 2 cars, 2 motorcycles, 1 truck, 526.2ms\n",
      "Speed: 0.4ms pre-process, 263.1ms inference, 0.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp143\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets364.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets364.png: 448x640 10 persons, 4 motorcycles, 448x640 11 persons, 4 motorcycles, 667.9ms\n",
      "Speed: 0.4ms pre-process, 333.9ms inference, 3.4ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp144\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets358.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets358.png: 480x640 2 persons, 1 car, 1 motorcycle, 1 potted plant, 480x640 3 persons, 1 car, 1 motorcycle, 1 cup, 2 potted plants, 752.2ms\n",
      "Speed: 0.3ms pre-process, 376.1ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp145\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets359.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets359.png: 352x640 2 persons, 1 bicycle, 1 motorcycle, 1 truck, 1 dog, 1 chair, 352x640 2 persons, 2 bicycles, 1 motorcycle, 1 truck, 523.5ms\n",
      "Speed: 0.3ms pre-process, 261.8ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp146\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets403.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets403.png: 384x640 11 persons, 9 bicycles, 2 cars, 1 motorcycle, 1 traffic light, 1 backpack, 384x640 9 persons, 10 bicycles, 2 cars, 1 motorcycle, 1 traffic light, 3 backpacks, 561.4ms\n",
      "Speed: 0.3ms pre-process, 280.7ms inference, 1.0ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp147\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets365.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets365.png: 448x640 7 persons, 4 bicycles, 2 cars, 2 trucks, 1 traffic light, 1 handbag, 448x640 8 persons, 5 bicycles, 3 cars, 2 trucks, 1 traffic light, 646.7ms\n",
      "Speed: 0.3ms pre-process, 323.3ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp148\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets371.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets371.png: 416x640 9 persons, 4 motorcycles, 416x640 10 persons, 5 motorcycles, 648.3ms\n",
      "Speed: 0.4ms pre-process, 324.2ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp149\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets417.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets417.png: 448x640 2 persons, 2 bicycles, 1 backpack, 2 sports balls, 448x640 2 persons, 2 bicycles, 2 sports balls, 672.4ms\n",
      "Speed: 0.4ms pre-process, 336.2ms inference, 1.1ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp150\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets198.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets198.png: 640x608 2 persons, 1 bicycle, 1 handbag, 640x608 3 persons, 1 bicycle, 1 handbag, 909.6ms\n",
      "Speed: 1.4ms pre-process, 454.8ms inference, 1.2ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp151\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets629.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets629.png: 448x640 1 person, 1 motorcycle, 448x640 1 person, 1 motorcycle, 654.8ms\n",
      "Speed: 0.4ms pre-process, 327.4ms inference, 1.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp152\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets167.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets167.png: 384x640 1 person, 1 motorcycle, 384x640 1 person, 1 motorcycle, 612.6ms\n",
      "Speed: 0.3ms pre-process, 306.3ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp153\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets601.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets601.png: 640x480 1 person, 1 motorcycle, 1 bird, 640x480 1 person, 1 motorcycle, 722.2ms\n",
      "Speed: 0.3ms pre-process, 361.1ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp154\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets615.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets615.png: 448x640 2 persons, 1 bicycle, 3 cars, 1 bus, 3 traffic lights, 1 backpack, 448x640 2 persons, 1 bicycle, 3 cars, 1 bus, 6 traffic lights, 1 backpack, 648.0ms\n",
      "Speed: 0.4ms pre-process, 324.0ms inference, 0.9ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp155\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets173.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets173.png: 544x640 6 persons, 1 car, 3 motorcycles, 5 buss, 1 handbag, 544x640 9 persons, 1 car, 4 motorcycles, 4 buss, 1 handbag, 802.4ms\n",
      "Speed: 0.4ms pre-process, 401.2ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp156\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets749.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets749.png: 512x640 1 person, 1 motorcycle, 512x640 1 person, 1 motorcycle, 804.0ms\n",
      "Speed: 0.5ms pre-process, 402.0ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp157\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets761.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets761.png: 384x640 1 person, 1 motorcycle, 384x640 1 person, 1 motorcycle, 556.3ms\n",
      "Speed: 0.3ms pre-process, 278.2ms inference, 0.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp158\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets588.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets588.png: 416x640 4 persons, 1 car, 2 motorcycles, 1 bus, 2 backpacks, 416x640 4 persons, 1 car, 1 motorcycle, 2 buss, 1 backpack, 665.7ms\n",
      "Speed: 0.6ms pre-process, 332.9ms inference, 1.1ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp159\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets13.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets13.png: 608x640 1 person, 1 motorcycle, 608x640 1 person, 1 motorcycle, 870.8ms\n",
      "Speed: 0.6ms pre-process, 435.4ms inference, 1.0ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp160\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets239.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets239.png: 448x640 2 persons, 6 cars, 1 motorcycle, 1 bus, 448x640 2 persons, 6 cars, 1 motorcycle, 1 bus, 670.2ms\n",
      "Speed: 0.5ms pre-process, 335.1ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp161\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets577.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets577.png: 448x640 1 person, 3 cars, 1 tennis racket, 448x640 1 person, 1 bicycle, 3 cars, 727.0ms\n",
      "Speed: 0.1ms pre-process, 363.5ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp162\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets211.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets211.png: 448x640 1 person, 1 bicycle, 1 car, 448x640 1 person, 1 bicycle, 1 car, 694.8ms\n",
      "Speed: 0.3ms pre-process, 347.4ms inference, 1.0ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp163\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets205.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets205.png: 448x640 1 person, 1 bicycle, 448x640 1 person, 1 bicycle, 695.7ms\n",
      "Speed: 0.4ms pre-process, 347.8ms inference, 0.9ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp164\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets563.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets563.png: 416x640 3 persons, 1 car, 6 motorcycles, 1 truck, 416x640 4 persons, 6 motorcycles, 1 truck, 660.2ms\n",
      "Speed: 1.1ms pre-process, 330.1ms inference, 1.4ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp165\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets538.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets538.png: 640x640 1 person, 1 motorcycle, 640x640 1 person, 1 motorcycle, 947.4ms\n",
      "Speed: 0.6ms pre-process, 473.7ms inference, 1.2ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp166\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets262.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets262.png: 448x640 5 persons, 1 motorcycle, 1 umbrella, 448x640 4 persons, 1 motorcycle, 1 umbrella, 617.6ms\n",
      "Speed: 0.3ms pre-process, 308.8ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp167\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets504.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets504.png: 480x640 3 persons, 1 motorcycle, 480x640 3 persons, 1 motorcycle, 714.9ms\n",
      "Speed: 0.3ms pre-process, 357.5ms inference, 1.4ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp168\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets510.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets510.png: 448x640 5 persons, 5 motorcycles, 1 bus, 1 handbag, 448x640 5 persons, 1 car, 4 motorcycles, 1 bus, 1 truck, 1 handbag, 755.2ms\n",
      "Speed: 1.8ms pre-process, 377.6ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp169\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets276.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets276.png: 384x640 3 persons, 5 cars, 5 motorcycles, 1 cup, 384x640 2 persons, 4 cars, 5 motorcycles, 1 cell phone, 593.3ms\n",
      "Speed: 0.3ms pre-process, 296.6ms inference, 1.4ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp170\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets48.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets48.png: 640x480 1 person, 1 bicycle, 1 car, 640x480 1 person, 1 bicycle, 1 car, 755.1ms\n",
      "Speed: 0.3ms pre-process, 377.6ms inference, 1.2ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp171\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets289.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets289.png: 640x544 1 person, 1 motorcycle, 640x544 1 person, 1 motorcycle, 773.0ms\n",
      "Speed: 0.4ms pre-process, 386.5ms inference, 0.9ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp172\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets60.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets60.png: 480x640 4 persons, 3 motorcycles, 480x640 4 persons, 3 motorcycles, 643.9ms\n",
      "Speed: 0.3ms pre-process, 322.0ms inference, 0.9ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp173\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets74.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets74.png: 448x640 2 persons, 4 motorcycles, 448x640 3 persons, 4 motorcycles, 659.6ms\n",
      "Speed: 0.4ms pre-process, 329.8ms inference, 1.4ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp174\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets706.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets706.png: 480x640 2 persons, 1 motorcycle, 480x640 4 persons, 1 motorcycle, 707.3ms\n",
      "Speed: 0.3ms pre-process, 353.6ms inference, 0.9ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp175\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets712.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets712.png: 352x640 1 person, 1 bicycle, 352x640 1 person, 1 bicycle, 564.6ms\n",
      "Speed: 0.3ms pre-process, 282.3ms inference, 0.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp176\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets128.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets128.png: 448x640 2 persons, 1 motorcycle, 448x640 2 persons, 1 motorcycle, 704.1ms\n",
      "Speed: 0.3ms pre-process, 352.0ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp177\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets672.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets672.png: 384x640 7 persons, 6 bicycles, 3 cars, 1 truck, 384x640 7 persons, 6 bicycles, 3 cars, 583.0ms\n",
      "Speed: 0.3ms pre-process, 291.5ms inference, 1.2ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp178\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets114.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets114.png: 480x640 7 persons, 6 bicycles, 5 cars, 1 handbag, 480x640 7 persons, 6 bicycles, 5 cars, 705.4ms\n",
      "Speed: 0.4ms pre-process, 352.7ms inference, 0.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp179\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets100.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets100.png: 512x640 2 persons, 1 car, 1 motorcycle, 1 potted plant, 512x640 2 persons, 1 car, 1 motorcycle, 1 potted plant, 835.5ms\n",
      "Speed: 0.4ms pre-process, 417.8ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp180\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets666.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets666.png: 448x640 1 person, 1 motorcycle, 448x640 1 person, 1 motorcycle, 684.9ms\n",
      "Speed: 0.4ms pre-process, 342.4ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp181\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets699.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets699.png: 480x640 12 persons, 480x640 11 persons, 838.5ms\n",
      "Speed: 0.5ms pre-process, 419.2ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp182\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets458.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets458.png: 416x640 5 persons, 1 car, 3 motorcycles, 416x640 4 persons, 1 car, 3 motorcycles, 637.1ms\n",
      "Speed: 0.4ms pre-process, 318.6ms inference, 0.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp183\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets316.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets316.png: 640x448 1 person, 1 bicycle, 1 truck, 1 bench, 1 backpack, 640x448 1 person, 1 bicycle, 1 truck, 1 bench, 1 backpack, 918.4ms\n",
      "Speed: 0.6ms pre-process, 459.2ms inference, 0.9ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp184\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets470.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets470.png: 640x480 2 persons, 2 cars, 2 motorcycles, 640x480 2 persons, 3 cars, 2 motorcycles, 1 backpack, 922.5ms\n",
      "Speed: 0.4ms pre-process, 461.3ms inference, 1.1ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp185\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets464.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets464.png: 544x640 1 person, 1 bicycle, 2 cars, 544x640 1 person, 1 bicycle, 1 car, 1219.5ms\n",
      "Speed: 0.4ms pre-process, 609.7ms inference, 1.1ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp186\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets302.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets302.png: 416x640 2 persons, 1 motorcycle, 416x640 3 persons, 1 motorcycle, 649.2ms\n",
      "Speed: 1.3ms pre-process, 324.6ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp187\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets465.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets465.png: 416x640 8 persons, 7 motorcycles, 1 kite, 416x640 10 persons, 6 motorcycles, 667.5ms\n",
      "Speed: 0.5ms pre-process, 333.7ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp188\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets303.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets303.png: 352x640 13 persons, 2 cars, 7 motorcycles, 2 trucks, 1 traffic light, 352x640 13 persons, 3 cars, 7 motorcycles, 4 trucks, 1 traffic light, 536.4ms\n",
      "Speed: 0.2ms pre-process, 268.2ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp189\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets317.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets317.png: 448x640 5 persons, 1 motorcycle, 1 umbrella, 448x640 4 persons, 1 motorcycle, 1 umbrella, 704.9ms\n",
      "Speed: 0.4ms pre-process, 352.4ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp190\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets471.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets471.png: 448x640 4 persons, 2 motorcycles, 2 buss, 1 truck, 1 cell phone, 448x640 5 persons, 2 motorcycles, 1 bus, 2 trucks, 1 cell phone, 710.0ms\n",
      "Speed: 0.4ms pre-process, 355.0ms inference, 0.9ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp191\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets459.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets459.png: 384x640 3 persons, 4 motorcycles, 384x640 3 persons, 4 motorcycles, 555.1ms\n",
      "Speed: 0.3ms pre-process, 277.6ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp192\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets698.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets698.png: 640x640 1 person, 1 motorcycle, 640x640 1 person, 1 motorcycle, 901.2ms\n",
      "Speed: 0.5ms pre-process, 450.6ms inference, 2.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp193\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets101.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets101.png: 384x640 1 person, 1 car, 1 motorcycle, 1 truck, 384x640 1 person, 1 car, 2 motorcycles, 1 truck, 558.1ms\n",
      "Speed: 0.4ms pre-process, 279.0ms inference, 3.1ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp194\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets667.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets667.png: 384x640 1 person, 2 cars, 1 motorcycle, 1 backpack, 384x640 1 person, 1 bicycle, 2 cars, 1 motorcycle, 1 backpack, 575.9ms\n",
      "Speed: 0.5ms pre-process, 288.0ms inference, 0.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp195\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets673.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets673.png: 448x640 8 persons, 5 bicycles, 448x640 8 persons, 5 bicycles, 625.2ms\n",
      "Speed: 0.4ms pre-process, 312.6ms inference, 0.9ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp196\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets115.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets115.png: 416x640 7 persons, 7 motorcycles, 416x640 9 persons, 9 motorcycles, 631.7ms\n",
      "Speed: 0.5ms pre-process, 315.9ms inference, 0.9ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp197\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets129.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets129.png: 448x640 1 person, 1 bicycle, 448x640 1 person, 1 bicycle, 2 bottles, 686.3ms\n",
      "Speed: 0.4ms pre-process, 343.2ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp198\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets713.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets713.png: 448x640 3 persons, 2 motorcycles, 448x640 2 persons, 3 motorcycles, 707.7ms\n",
      "Speed: 0.4ms pre-process, 353.9ms inference, 0.9ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp199\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets707.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets707.png: 480x640 3 persons, 1 motorcycle, 480x640 3 persons, 1 motorcycle, 726.2ms\n",
      "Speed: 0.3ms pre-process, 363.1ms inference, 1.5ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp200\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets75.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets75.png: 480x640 8 persons, 4 bicycles, 2 cars, 1 clock, 480x640 8 persons, 4 bicycles, 2 cars, 1 clock, 727.2ms\n",
      "Speed: 0.4ms pre-process, 363.6ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp201\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets61.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets61.png: 480x640 7 persons, 2 motorcycles, 1 chair, 480x640 8 persons, 2 motorcycles, 1 chair, 693.6ms\n",
      "Speed: 0.4ms pre-process, 346.8ms inference, 1.3ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp202\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets49.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets49.png: 416x640 2 persons, 1 motorcycle, 416x640 3 persons, 1 motorcycle, 634.8ms\n",
      "Speed: 0.4ms pre-process, 317.4ms inference, 3.0ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp203\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets288.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets288.png: 416x640 5 persons, 1 car, 3 motorcycles, 416x640 4 persons, 1 car, 3 motorcycles, 591.9ms\n",
      "Speed: 0.4ms pre-process, 295.9ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp204\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets511.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets511.png: 448x640 3 persons, 3 bicycles, 1 stop sign, 448x640 3 persons, 3 bicycles, 1 stop sign, 676.3ms\n",
      "Speed: 0.6ms pre-process, 338.2ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp205\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets277.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets277.png: 384x640 9 persons, 5 motorcycles, 384x640 10 persons, 5 motorcycles, 561.7ms\n",
      "Speed: 1.2ms pre-process, 280.8ms inference, 0.9ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp206\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets263.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets263.png: 448x640 1 person, 1 motorcycle, 448x640 1 person, 1 motorcycle, 772.8ms\n",
      "Speed: 0.5ms pre-process, 386.4ms inference, 1.2ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp207\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets505.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets505.png: 448x640 7 persons, 2 bicycles, 2 cars, 1 potted plant, 448x640 6 persons, 2 bicycles, 2 cars, 807.1ms\n",
      "Speed: 0.3ms pre-process, 403.5ms inference, 1.2ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp208\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets539.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets539.png: 448x640 2 persons, 1 motorcycle, 448x640 2 persons, 1 motorcycle, 941.6ms\n",
      "Speed: 0.5ms pre-process, 470.8ms inference, 0.9ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp209\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets249.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets249.png: 640x448 1 person, 1 baseball bat, 640x448 1 person, 1 car, 941.9ms\n",
      "Speed: 0.5ms pre-process, 470.9ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp210\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets88.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets88.png: 448x640 2 persons, 1 motorcycle, 2 parking meters, 448x640 2 persons, 2 motorcycles, 2 parking meters, 891.8ms\n",
      "Speed: 0.4ms pre-process, 445.9ms inference, 2.4ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp211\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets275.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets275.png: 640x640 1 person, 1 bicycle, 640x640 1 person, 1 bicycle, 1277.3ms\n",
      "Speed: 0.2ms pre-process, 638.7ms inference, 2.0ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp212\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets513.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets513.png: 640x608 1 person, 1 motorcycle, 640x608 1 person, 1 motorcycle, 1113.3ms\n",
      "Speed: 0.7ms pre-process, 556.7ms inference, 1.1ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp213\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets507.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets507.png: 448x640 5 persons, 3 bicycles, 1 car, 1 umbrella, 448x640 5 persons, 3 bicycles, 1 car, 1 fire hydrant, 783.8ms\n",
      "Speed: 0.4ms pre-process, 391.9ms inference, 1.1ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp214\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets261.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets261.png: 512x640 3 persons, 2 motorcycles, 2 traffic lights, 512x640 3 persons, 1 bicycle, 2 motorcycles, 2 traffic lights, 955.7ms\n",
      "Speed: 0.5ms pre-process, 477.9ms inference, 1.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp215\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets77.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets77.png: 480x640 3 persons, 2 motorcycles, 480x640 3 persons, 2 motorcycles, 844.5ms\n",
      "Speed: 0.4ms pre-process, 422.3ms inference, 0.9ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp216\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets63.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets63.png: 640x384 2 persons, 1 bicycle, 640x384 2 persons, 1 bicycle, 1 backpack, 707.6ms\n",
      "Speed: 0.4ms pre-process, 353.8ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp217\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets739.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets739.png: 384x640 2 persons, 1 motorcycle, 384x640 2 persons, 1 motorcycle, 689.9ms\n",
      "Speed: 0.4ms pre-process, 344.9ms inference, 1.1ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp218\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets711.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets711.png: 640x448 3 persons, 1 bicycle, 640x448 3 persons, 1 bicycle, 753.8ms\n",
      "Speed: 0.5ms pre-process, 376.9ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp219\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets705.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets705.png: 448x640 1 person, 1 car, 1 motorcycle, 448x640 1 person, 1 car, 1 motorcycle, 1 bench, 1084.4ms\n",
      "Speed: 0.7ms pre-process, 542.2ms inference, 1.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp220\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets659.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets659.png: 384x640 1 person, 3 cars, 2 motorcycles, 384x640 1 person, 4 cars, 1 motorcycle, 882.7ms\n",
      "Speed: 0.5ms pre-process, 441.4ms inference, 1.3ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp221\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets665.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets665.png: 480x640 7 persons, 7 motorcycles, 480x640 7 persons, 8 motorcycles, 911.6ms\n",
      "Speed: 0.5ms pre-process, 455.8ms inference, 1.5ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp222\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets103.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets103.png: 448x640 3 persons, 1 motorcycle, 1 handbag, 448x640 3 persons, 1 motorcycle, 1 handbag, 891.9ms\n",
      "Speed: 0.8ms pre-process, 445.9ms inference, 1.5ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp223\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets117.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets117.png: 640x480 2 persons, 1 bicycle, 640x480 2 persons, 1 bicycle, 890.6ms\n",
      "Speed: 0.4ms pre-process, 445.3ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp224\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets671.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets671.png: 384x640 13 persons, 8 motorcycles, 384x640 11 persons, 8 motorcycles, 624.7ms\n",
      "Speed: 1.6ms pre-process, 312.3ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp225\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets329.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets329.png: 448x640 4 persons, 4 bicycles, 448x640 4 persons, 4 bicycles, 678.1ms\n",
      "Speed: 0.4ms pre-process, 339.0ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp226\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets301.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets301.png: 640x448 1 person, 1 bicycle, 640x448 1 person, 1 bicycle, 790.1ms\n",
      "Speed: 1.9ms pre-process, 395.0ms inference, 0.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp227\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets467.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets467.png: 480x640 1 person, 1 motorcycle, 1 chair, 480x640 1 person, 1 motorcycle, 2 chairs, 758.3ms\n",
      "Speed: 0.4ms pre-process, 379.2ms inference, 0.9ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp228\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets473.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets473.png: 480x640 1 person, 1 motorcycle, 480x640 1 person, 1 motorcycle, 1008.3ms\n",
      "Speed: 0.4ms pre-process, 504.1ms inference, 0.9ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp229\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets315.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets315.png: 448x640 2 persons, 1 bicycle, 3 cars, 448x640 2 persons, 2 cars, 2 motorcycles, 1 backpack, 838.8ms\n",
      "Speed: 0.4ms pre-process, 419.4ms inference, 1.4ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp230\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets498.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets498.png: 448x640 2 persons, 1 motorcycle, 448x640 2 persons, 1 motorcycle, 866.8ms\n",
      "Speed: 0.2ms pre-process, 433.4ms inference, 2.2ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp231\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets499.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets499.png: 448x640 8 persons, 1 bicycle, 448x640 9 persons, 1 bicycle, 715.1ms\n",
      "Speed: 0.6ms pre-process, 357.5ms inference, 1.2ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp232\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets472.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets472.png: 416x640 3 persons, 4 bicycles, 2 backpacks, 416x640 4 persons, 4 bicycles, 2 backpacks, 679.5ms\n",
      "Speed: 0.4ms pre-process, 339.8ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp233\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets314.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets314.png: 480x640 5 persons, 1 car, 2 motorcycles, 2 trucks, 480x640 6 persons, 3 motorcycles, 2 trucks, 725.0ms\n",
      "Speed: 0.3ms pre-process, 362.5ms inference, 1.1ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp234\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets300.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets300.png: 448x640 2 persons, 1 car, 1 motorcycle, 448x640 2 persons, 1 car, 1 motorcycle, 611.8ms\n",
      "Speed: 0.5ms pre-process, 305.9ms inference, 0.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp235\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets466.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets466.png: 480x640 2 persons, 1 car, 2 motorcycles, 1 handbag, 480x640 2 persons, 1 car, 3 motorcycles, 771.6ms\n",
      "Speed: 1.4ms pre-process, 385.8ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp236\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets328.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets328.png: 480x640 2 persons, 1 car, 1 motorcycle, 1 potted plant, 480x640 3 persons, 1 car, 1 motorcycle, 1 cup, 2 potted plants, 747.6ms\n",
      "Speed: 0.4ms pre-process, 373.8ms inference, 2.0ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp237\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets116.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets116.png: 448x640 11 persons, 11 bicycles, 448x640 12 persons, 12 bicycles, 4 backpacks, 803.3ms\n",
      "Speed: 0.4ms pre-process, 401.7ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp238\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets670.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets670.png: 480x640 5 persons, 1 bicycle, 1 motorcycle, 1 bus, 1 traffic light, 1 stop sign, 2 handbags, 480x640 5 persons, 1 bicycle, 1 motorcycle, 1 bus, 1 fire hydrant, 1 stop sign, 4 handbags, 810.8ms\n",
      "Speed: 0.4ms pre-process, 405.4ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp239\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets664.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets664.png: 480x640 8 persons, 1 bicycle, 1 car, 1 handbag, 1 chair, 1 dining table, 480x640 4 persons, 1 bicycle, 1 car, 1 backpack, 2 handbags, 1 chair, 1 dining table, 1 cell phone, 761.5ms\n",
      "Speed: 0.2ms pre-process, 380.8ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp240\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets102.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets102.png: 640x640 4 persons, 2 bicycles, 1 car, 640x640 4 persons, 2 bicycles, 2 cars, 1361.8ms\n",
      "Speed: 0.8ms pre-process, 680.9ms inference, 1.5ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp241\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets658.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets658.png: 384x640 1 person, 2 cars, 1 motorcycle, 384x640 1 person, 2 cars, 1 motorcycle, 664.5ms\n",
      "Speed: 0.4ms pre-process, 332.3ms inference, 1.0ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp242\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets704.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets704.png: 480x640 2 persons, 3 bicycles, 3 backpacks, 480x640 3 persons, 2 bicycles, 2 backpacks, 1 handbag, 933.4ms\n",
      "Speed: 0.4ms pre-process, 466.7ms inference, 1.0ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp243\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets710.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets710.png: 416x640 16 persons, 12 bicycles, 1 car, 1 truck, 3 traffic lights, 3 backpacks, 416x640 14 persons, 12 bicycles, 2 cars, 1 truck, 6 traffic lights, 4 backpacks, 630.5ms\n",
      "Speed: 0.4ms pre-process, 315.3ms inference, 1.0ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp244\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets738.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets738.png: 640x448 1 person, 1 bicycle, 640x448 1 person, 1 bicycle, 803.5ms\n",
      "Speed: 0.2ms pre-process, 401.7ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp245\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets62.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets62.png: 640x512 1 person, 1 car, 1 motorcycle, 640x512 1 person, 2 cars, 1 motorcycle, 1003.7ms\n",
      "Speed: 0.5ms pre-process, 501.8ms inference, 1.1ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp246\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets76.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets76.png: 416x640 10 persons, 6 motorcycles, 1 bus, 416x640 11 persons, 6 motorcycles, 1 bus, 1033.4ms\n",
      "Speed: 0.4ms pre-process, 516.7ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp247\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets506.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets506.png: 576x640 4 persons, 2 sports balls, 576x640 4 persons, 2 sports balls, 1 skateboard, 1132.6ms\n",
      "Speed: 0.4ms pre-process, 566.3ms inference, 1.1ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp248\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets260.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets260.png: 448x640 1 person, 1 bicycle, 3 cars, 1 motorcycle, 448x640 1 person, 1 bicycle, 3 cars, 2 motorcycles, 850.3ms\n",
      "Speed: 0.5ms pre-process, 425.2ms inference, 1.3ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp249\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets274.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets274.png: 480x640 4 persons, 1 motorcycle, 480x640 4 persons, 3 motorcycles, 820.9ms\n",
      "Speed: 2.8ms pre-process, 410.5ms inference, 1.4ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp250\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets512.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets512.png: 480x640 1 person, 1 motorcycle, 480x640 1 person, 1 motorcycle, 928.2ms\n",
      "Speed: 0.4ms pre-process, 464.1ms inference, 0.9ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp251\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets248.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets248.png: 384x640 1 person, 1 motorcycle, 2 cows, 384x640 2 persons, 1 motorcycle, 1 cow, 700.2ms\n",
      "Speed: 0.5ms pre-process, 350.1ms inference, 0.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp252\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets89.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets89.png: 384x640 3 persons, 5 cars, 5 motorcycles, 1 cup, 384x640 2 persons, 4 cars, 5 motorcycles, 1 cell phone, 700.8ms\n",
      "Speed: 0.4ms pre-process, 350.4ms inference, 1.0ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp253\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets516.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets516.png: 448x640 4 persons, 4 bicycles, 1 potted plant, 448x640 5 persons, 2 bicycles, 1 handbag, 1 cell phone, 704.7ms\n",
      "Speed: 0.4ms pre-process, 352.3ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp254\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets270.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets270.png: 640x640 1 person, 1 bicycle, 640x640 1 person, 1 bicycle, 1133.7ms\n",
      "Speed: 0.5ms pre-process, 566.9ms inference, 0.9ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp255\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets264.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets264.png: 480x640 10 persons, 7 bicycles, 1 bus, 480x640 9 persons, 7 bicycles, 1 bus, 1 handbag, 749.3ms\n",
      "Speed: 0.4ms pre-process, 374.7ms inference, 2.2ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp256\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets502.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets502.png: 352x640 2 persons, 1 bicycle, 10 cars, 1 truck, 3 backpacks, 352x640 2 persons, 2 bicycles, 10 cars, 2 backpacks, 546.3ms\n",
      "Speed: 0.1ms pre-process, 273.2ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp257\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets258.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets258.png: 640x480 2 persons, 2 cars, 2 motorcycles, 640x480 2 persons, 3 cars, 2 motorcycles, 1 backpack, 866.8ms\n",
      "Speed: 0.5ms pre-process, 433.4ms inference, 1.0ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp258\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets99.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets99.png: 416x640 4 persons, 4 bicycles, 416x640 5 persons, 4 bicycles, 1 stop sign, 705.3ms\n",
      "Speed: 0.4ms pre-process, 352.6ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp259\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets72.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets72.png: 416x640 3 persons, 1 bicycle, 416x640 3 persons, 1 bicycle, 870.5ms\n",
      "Speed: 0.4ms pre-process, 435.3ms inference, 1.0ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp260\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets66.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets66.png: 480x640 3 persons, 1 motorcycle, 480x640 3 persons, 1 motorcycle, 1011.3ms\n",
      "Speed: 0.5ms pre-process, 505.6ms inference, 1.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp261\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets714.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets714.png: 640x480 2 persons, 1 bicycle, 1 truck, 640x480 2 persons, 1 bicycle, 1 truck, 930.6ms\n",
      "Speed: 0.6ms pre-process, 465.3ms inference, 1.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp262\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets700.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets700.png: 512x640 6 persons, 5 bicycles, 1 car, 1 backpack, 1 potted plant, 512x640 6 persons, 5 bicycles, 2 cars, 1 backpack, 1 handbag, 1 potted plant, 975.4ms\n",
      "Speed: 0.5ms pre-process, 487.7ms inference, 1.9ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp263\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets728.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets728.png: 448x640 3 persons, 3 bicycles, 448x640 3 persons, 3 bicycles, 816.8ms\n",
      "Speed: 0.3ms pre-process, 408.4ms inference, 4.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp264\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets106.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets106.png: 448x640 3 persons, 3 bicycles, 448x640 3 persons, 3 bicycles, 707.2ms\n",
      "Speed: 0.4ms pre-process, 353.6ms inference, 1.3ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp265\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets660.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets660.png: 384x640 8 persons, 7 bicycles, 2 cars, 1 dog, 2 backpacks, 384x640 8 persons, 7 bicycles, 1 car, 1 dog, 3 backpacks, 519.8ms\n",
      "Speed: 0.5ms pre-process, 259.9ms inference, 0.9ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp266\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets674.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets674.png: 544x640 2 persons, 2 bicycles, 544x640 2 persons, 2 bicycles, 773.2ms\n",
      "Speed: 0.4ms pre-process, 386.6ms inference, 1.0ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp267\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets112.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets112.png: 384x640 3 persons, 2 cars, 2 motorcycles, 1 truck, 384x640 3 persons, 2 cars, 2 motorcycles, 1 truck, 537.9ms\n",
      "Speed: 0.4ms pre-process, 269.0ms inference, 1.1ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp268\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets648.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets648.png: 448x640 2 persons, 448x640 2 persons, 693.5ms\n",
      "Speed: 0.4ms pre-process, 346.8ms inference, 1.1ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp269\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets462.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets462.png: 288x640 9 persons, 2 bicycles, 1 dog, 2 backpacks, 288x640 10 persons, 3 bicycles, 1 dog, 2 backpacks, 508.4ms\n",
      "Speed: 0.4ms pre-process, 254.2ms inference, 0.9ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp270\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets304.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets304.png: 448x640 11 persons, 6 motorcycles, 2 umbrellas, 448x640 12 persons, 6 motorcycles, 1 backpack, 1 umbrella, 701.8ms\n",
      "Speed: 0.4ms pre-process, 350.9ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp271\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets310.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets310.png: 448x640 1 person, 1 bicycle, 448x640 1 person, 1 bicycle, 769.7ms\n",
      "Speed: 0.4ms pre-process, 384.9ms inference, 1.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp272\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets476.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets476.png: 384x640 3 persons, 3 motorcycles, 384x640 3 persons, 3 motorcycles, 554.0ms\n",
      "Speed: 0.3ms pre-process, 277.0ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp273\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets338.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets338.png: 512x640 14 persons, 11 bicycles, 3 cars, 1 bus, 512x640 15 persons, 14 bicycles, 4 cars, 1 bus, 1019.9ms\n",
      "Speed: 1.0ms pre-process, 510.0ms inference, 1.2ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp274\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets489.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets489.png: 640x448 3 persons, 3 bicycles, 2 backpacks, 640x448 3 persons, 3 bicycles, 2 backpacks, 809.5ms\n",
      "Speed: 0.4ms pre-process, 404.7ms inference, 1.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp275\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets488.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets488.png: 512x640 2 persons, 2 bicycles, 512x640 2 persons, 1 bicycle, 780.8ms\n",
      "Speed: 0.7ms pre-process, 390.4ms inference, 1.2ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp276\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets339.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets339.png: 640x640 2 persons, 2 bicycles, 640x640 2 persons, 2 bicycles, 1139.6ms\n",
      "Speed: 0.6ms pre-process, 569.8ms inference, 1.9ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp277\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets311.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets311.png: 480x640 6 persons, 2 bicycles, 2 cars, 480x640 7 persons, 2 bicycles, 2 cars, 750.0ms\n",
      "Speed: 0.4ms pre-process, 375.0ms inference, 1.0ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp278\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets477.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets477.png: 416x640 1 person, 1 motorcycle, 416x640 1 person, 1 motorcycle, 687.1ms\n",
      "Speed: 0.7ms pre-process, 343.6ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp279\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets463.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets463.png: 448x640 4 persons, 3 bicycles, 1 backpack, 448x640 4 persons, 3 bicycles, 2 backpacks, 678.5ms\n",
      "Speed: 0.4ms pre-process, 339.2ms inference, 0.5ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp280\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets305.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets305.png: 416x640 4 persons, 1 car, 2 motorcycles, 1 bus, 2 backpacks, 416x640 4 persons, 1 car, 1 motorcycle, 2 buss, 1 backpack, 787.0ms\n",
      "Speed: 0.4ms pre-process, 393.5ms inference, 1.9ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp281\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets649.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets649.png: 640x512 1 person, 640x512 1 person, 939.7ms\n",
      "Speed: 0.4ms pre-process, 469.8ms inference, 0.9ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp282\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets675.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets675.png: 640x640 1 person, 1 car, 1 motorcycle, 640x640 1 person, 1 car, 1 motorcycle, 857.9ms\n",
      "Speed: 0.5ms pre-process, 428.9ms inference, 1.1ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp283\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets113.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets113.png: 480x640 2 persons, 1 motorcycle, 2 backpacks, 480x640 2 persons, 1 motorcycle, 2 backpacks, 765.9ms\n",
      "Speed: 0.4ms pre-process, 383.0ms inference, 0.9ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp284\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets107.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets107.png: 192x640 1 person, 1 backpack, 192x640 1 person, 1 backpack, 382.5ms\n",
      "Speed: 0.3ms pre-process, 191.2ms inference, 0.4ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp285\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets661.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets661.png: 448x640 2 persons, 2 motorcycles, 1 handbag, 448x640 2 persons, 2 motorcycles, 1 handbag, 759.2ms\n",
      "Speed: 1.4ms pre-process, 379.6ms inference, 0.9ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp286\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets729.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets729.png: 448x640 2 persons, 1 bicycle, 448x640 2 persons, 2 bicycles, 690.5ms\n",
      "Speed: 0.3ms pre-process, 345.2ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp287\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets701.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets701.png: 384x640 2 persons, 2 bicycles, 3 bottles, 384x640 2 persons, 2 bicycles, 2 bottles, 577.9ms\n",
      "Speed: 0.3ms pre-process, 289.0ms inference, 1.1ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp288\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets715.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets715.png: 448x640 1 person, 448x640 1 person, 671.8ms\n",
      "Speed: 0.5ms pre-process, 335.9ms inference, 0.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp289\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets67.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets67.png: 576x640 2 persons, 7 cars, 1 bench, 1 backpack, 576x640 2 persons, 2 bicycles, 8 cars, 1 backpack, 821.1ms\n",
      "Speed: 0.6ms pre-process, 410.6ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp290\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets73.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets73.png: 480x640 2 persons, 1 motorcycle, 1 handbag, 480x640 2 persons, 1 motorcycle, 754.0ms\n",
      "Speed: 0.9ms pre-process, 377.0ms inference, 2.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp291\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets259.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets259.png: 384x640 4 persons, 384x640 4 persons, 599.0ms\n",
      "Speed: 0.7ms pre-process, 299.5ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp292\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets98.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets98.png: 384x640 2 persons, 4 cars, 1 motorcycle, 3 trucks, 384x640 3 persons, 4 cars, 2 motorcycles, 2 trucks, 1 handbag, 597.4ms\n",
      "Speed: 0.8ms pre-process, 298.7ms inference, 1.3ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp293\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets265.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets265.png: 448x640 1 person, 1 bicycle, 1 car, 448x640 1 person, 1 bicycle, 1 car, 676.4ms\n",
      "Speed: 0.5ms pre-process, 338.2ms inference, 1.0ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp294\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets503.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets503.png: 448x640 1 person, 1 bicycle, 2 cars, 1 motorcycle, 1 backpack, 1 chair, 448x640 1 person, 1 bicycle, 1 car, 1 backpack, 1 chair, 637.7ms\n",
      "Speed: 0.4ms pre-process, 318.9ms inference, 2.3ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp295\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets517.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets517.png: 640x608 4 persons, 3 bicycles, 2 cars, 640x608 8 persons, 2 bicycles, 2 cars, 967.8ms\n",
      "Speed: 0.5ms pre-process, 483.9ms inference, 1.1ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp296\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets271.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets271.png: 480x640 5 persons, 4 bicycles, 1 bottle, 480x640 5 persons, 4 bicycles, 1 bottle, 874.1ms\n",
      "Speed: 0.7ms pre-process, 437.0ms inference, 1.5ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp297\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets501.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets501.png: 448x640 2 persons, 1 bicycle, 1 bottle, 448x640 2 persons, 1 bicycle, 1 bottle, 808.2ms\n",
      "Speed: 0.5ms pre-process, 404.1ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp298\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets267.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets267.png: 448x640 5 persons, 1 motorcycle, 1 umbrella, 448x640 4 persons, 1 motorcycle, 1 umbrella, 902.6ms\n",
      "Speed: 0.9ms pre-process, 451.3ms inference, 1.1ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp299\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets273.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets273.png: 480x640 5 persons, 5 cars, 4 motorcycles, 480x640 6 persons, 4 cars, 4 motorcycles, 850.9ms\n",
      "Speed: 0.5ms pre-process, 425.5ms inference, 0.9ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp300\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets515.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets515.png: 448x640 4 persons, 4 bicycles, 448x640 4 persons, 4 bicycles, 749.9ms\n",
      "Speed: 0.4ms pre-process, 375.0ms inference, 2.1ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp301\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets529.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets529.png: 480x640 3 persons, 2 bicycles, 11 cars, 1 truck, 480x640 3 persons, 2 bicycles, 12 cars, 1 truck, 703.5ms\n",
      "Speed: 0.4ms pre-process, 351.8ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp302\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets65.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets65.png: 384x640 3 persons, 2 bicycles, 384x640 3 persons, 2 bicycles, 720.7ms\n",
      "Speed: 0.4ms pre-process, 360.3ms inference, 1.0ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp303\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets71.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets71.png: 384x640 2 persons, 2 motorcycles, 384x640 2 persons, 2 motorcycles, 763.4ms\n",
      "Speed: 0.7ms pre-process, 381.7ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp304\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets59.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets59.png: 448x640 6 persons, 7 bicycles, 448x640 7 persons, 7 bicycles, 1 bottle, 705.9ms\n",
      "Speed: 0.3ms pre-process, 353.0ms inference, 2.3ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp305\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets298.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets298.png: 448x640 10 persons, 5 bicycles, 1 train, 2 backpacks, 448x640 9 persons, 7 bicycles, 3 backpacks, 2 handbags, 690.4ms\n",
      "Speed: 0.4ms pre-process, 345.2ms inference, 0.9ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp306\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets703.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets703.png: 384x640 3 persons, 2 bicycles, 384x640 3 persons, 2 bicycles, 755.1ms\n",
      "Speed: 0.4ms pre-process, 377.6ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp307\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets717.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets717.png: 544x640 8 persons, 1 bicycle, 2 cars, 1 motorcycle, 1 truck, 1 backpack, 544x640 11 persons, 1 bicycle, 3 cars, 1 motorcycle, 1 backpack, 1 handbag, 933.3ms\n",
      "Speed: 0.4ms pre-process, 466.6ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp308\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets111.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets111.png: 448x640 1 person, 1 motorcycle, 448x640 1 person, 1 motorcycle, 760.7ms\n",
      "Speed: 0.4ms pre-process, 380.3ms inference, 1.0ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp309\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets677.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets677.png: 448x640 2 persons, 1 motorcycle, 448x640 2 persons, 1 motorcycle, 783.1ms\n",
      "Speed: 0.4ms pre-process, 391.5ms inference, 1.2ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp310\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets663.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets663.png: 480x640 1 person, 1 motorcycle, 480x640 1 person, 1 motorcycle, 744.6ms\n",
      "Speed: 0.4ms pre-process, 372.3ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp311\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets105.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets105.png: 384x640 4 persons, 3 bicycles, 384x640 4 persons, 3 bicycles, 1 skateboard, 606.7ms\n",
      "Speed: 0.3ms pre-process, 303.3ms inference, 0.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp312\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets139.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets139.png: 320x640 1 person, 1 car, 1 motorcycle, 320x640 1 person, 1 car, 1 motorcycle, 530.8ms\n",
      "Speed: 0.4ms pre-process, 265.4ms inference, 1.5ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp313\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets688.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets688.png: 480x640 1 person, 1 bicycle, 480x640 1 person, 1 bicycle, 797.3ms\n",
      "Speed: 0.4ms pre-process, 398.6ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp314\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets475.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets475.png: 448x640 2 persons, 1 motorcycle, 448x640 2 persons, 1 motorcycle, 707.1ms\n",
      "Speed: 0.3ms pre-process, 353.5ms inference, 0.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp315\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets313.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets313.png: 320x640 6 persons, 4 motorcycles, 320x640 6 persons, 4 motorcycles, 1 suitcase, 489.9ms\n",
      "Speed: 0.2ms pre-process, 245.0ms inference, 0.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp316\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets307.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets307.png: 448x640 6 persons, 4 bicycles, 1 car, 448x640 6 persons, 5 bicycles, 1 car, 747.6ms\n",
      "Speed: 0.4ms pre-process, 373.8ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp317\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets461.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets461.png: 448x640 2 persons, 448x640 2 persons, 1 baseball bat, 819.8ms\n",
      "Speed: 0.5ms pre-process, 409.9ms inference, 1.1ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp318\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets449.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets449.png: 448x640 12 persons, 10 bicycles, 1 backpack, 448x640 14 persons, 11 bicycles, 1 backpack, 712.5ms\n",
      "Speed: 0.4ms pre-process, 356.3ms inference, 1.3ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp319\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets448.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets448.png: 480x640 2 persons, 1 car, 1 motorcycle, 1 potted plant, 480x640 3 persons, 1 car, 1 motorcycle, 1 cup, 2 potted plants, 804.7ms\n",
      "Speed: 0.4ms pre-process, 402.4ms inference, 1.0ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp320\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets306.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets306.png: 512x640 7 persons, 512x640 7 persons, 2 bicycles, 1060.0ms\n",
      "Speed: 0.5ms pre-process, 530.0ms inference, 1.2ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp321\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets460.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets460.png: 224x640 6 persons, 2 bicycles, 6 cars, 1 parking meter, 224x640 5 persons, 5 bicycles, 5 cars, 1 truck, 1 parking meter, 1 backpack, 427.2ms\n",
      "Speed: 0.2ms pre-process, 213.6ms inference, 1.1ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp322\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets474.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets474.png: 448x640 10 persons, 1 car, 8 motorcycles, 448x640 10 persons, 1 car, 6 motorcycles, 759.7ms\n",
      "Speed: 0.7ms pre-process, 379.8ms inference, 1.3ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp323\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets312.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets312.png: 448x640 2 persons, 1 bicycle, 448x640 2 persons, 1 bicycle, 649.0ms\n",
      "Speed: 0.2ms pre-process, 324.5ms inference, 0.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp324\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets689.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets689.png: 480x640 8 persons, 6 bicycles, 1 backpack, 480x640 8 persons, 7 bicycles, 2 cars, 806.0ms\n",
      "Speed: 0.4ms pre-process, 403.0ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp325\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets138.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets138.png: 448x640 2 persons, 2 bicycles, 1 car, 448x640 2 persons, 2 bicycles, 1 car, 1 backpack, 691.3ms\n",
      "Speed: 0.4ms pre-process, 345.6ms inference, 1.2ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp326\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets662.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets662.png: 416x640 1 person, 1 motorcycle, 416x640 1 person, 1 motorcycle, 688.9ms\n",
      "Speed: 0.2ms pre-process, 344.5ms inference, 1.0ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp327\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets104.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets104.png: 448x640 2 persons, 448x640 2 persons, 888.2ms\n",
      "Speed: 0.4ms pre-process, 444.1ms inference, 0.9ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp328\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets110.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets110.png: 448x640 16 persons, 9 bicycles, 3 cars, 5 buss, 1 truck, 1 dog, 448x640 13 persons, 9 bicycles, 4 cars, 6 buss, 1 truck, 1 dog, 672.9ms\n",
      "Speed: 0.3ms pre-process, 336.4ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp329\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets676.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets676.png: 480x640 7 persons, 3 bicycles, 2 traffic lights, 1 handbag, 480x640 7 persons, 5 bicycles, 2 traffic lights, 1 handbag, 885.8ms\n",
      "Speed: 3.6ms pre-process, 442.9ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp330\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets716.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets716.png: 384x640 2 persons, 1 motorcycle, 384x640 2 persons, 1 motorcycle, 617.0ms\n",
      "Speed: 0.4ms pre-process, 308.5ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp331\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets702.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets702.png: 416x640 8 persons, 2 bicycles, 5 cars, 1 truck, 416x640 8 persons, 2 bicycles, 7 cars, 1 truck, 2 traffic lights, 706.2ms\n",
      "Speed: 0.8ms pre-process, 353.1ms inference, 0.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp332\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets58.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets58.png: 544x640 8 persons, 1 bicycle, 2 cars, 1 motorcycle, 1 truck, 1 backpack, 544x640 11 persons, 1 bicycle, 3 cars, 1 motorcycle, 1 backpack, 1 handbag, 868.7ms\n",
      "Speed: 0.6ms pre-process, 434.3ms inference, 0.9ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp333\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets299.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets299.png: 640x640 6 persons, 5 cars, 6 motorcycles, 2 trucks, 2 traffic lights, 640x640 5 persons, 5 cars, 6 motorcycles, 2 trucks, 1 traffic light, 962.2ms\n",
      "Speed: 0.5ms pre-process, 481.1ms inference, 1.2ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp334\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets70.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets70.png: 384x640 5 persons, 1 motorcycle, 1 dog, 1 handbag, 384x640 5 persons, 1 motorcycle, 2 dogs, 580.7ms\n",
      "Speed: 0.3ms pre-process, 290.4ms inference, 2.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp335\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets64.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets64.png: 448x640 9 persons, 10 motorcycles, 448x640 9 persons, 12 motorcycles, 779.5ms\n",
      "Speed: 0.4ms pre-process, 389.7ms inference, 0.9ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp336\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets528.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets528.png: 416x640 9 persons, 4 motorcycles, 416x640 10 persons, 5 motorcycles, 751.6ms\n",
      "Speed: 0.4ms pre-process, 375.8ms inference, 0.9ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp337\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets272.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets272.png: 512x640 2 persons, 1 car, 1 motorcycle, 1 potted plant, 512x640 2 persons, 1 car, 1 motorcycle, 1 potted plant, 932.7ms\n",
      "Speed: 0.5ms pre-process, 466.3ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp338\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets514.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets514.png: 384x640 13 persons, 9 bicycles, 1 handbag, 384x640 13 persons, 10 bicycles, 1 traffic light, 675.5ms\n",
      "Speed: 0.7ms pre-process, 337.7ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp339\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets500.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets500.png: 640x544 1 person, 1 bicycle, 1 bus, 1 backpack, 640x544 1 person, 1 bicycle, 1 bus, 1 backpack, 908.7ms\n",
      "Speed: 0.6ms pre-process, 454.4ms inference, 1.1ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp340\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets266.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets266.png: 480x640 6 persons, 1 bicycle, 2 motorcycles, 1 truck, 480x640 8 persons, 1 bicycle, 1 car, 3 motorcycles, 882.8ms\n",
      "Speed: 0.5ms pre-process, 441.4ms inference, 1.0ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp341\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets519.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets519.png: 512x640 4 persons, 1 motorcycle, 1 truck, 512x640 4 persons, 1 motorcycle, 1 truck, 1090.3ms\n",
      "Speed: 0.4ms pre-process, 545.2ms inference, 1.4ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp342\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets243.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets243.png: 544x640 1 person, 544x640 1 person, 885.5ms\n",
      "Speed: 0.2ms pre-process, 442.7ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp343\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets525.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets525.png: 448x640 2 persons, 2 bicycles, 1 car, 448x640 2 persons, 2 bicycles, 1 car, 1 backpack, 701.8ms\n",
      "Speed: 0.5ms pre-process, 350.9ms inference, 1.0ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp344\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets82.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets82.png: 448x640 15 persons, 8 bicycles, 448x640 16 persons, 9 bicycles, 651.3ms\n",
      "Speed: 1.0ms pre-process, 325.7ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp345\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets531.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets531.png: 576x640 5 persons, 1 car, 4 motorcycles, 576x640 6 persons, 3 motorcycles, 811.2ms\n",
      "Speed: 0.4ms pre-process, 405.6ms inference, 0.9ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp346\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets96.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets96.png: 352x640 4 persons, 4 bicycles, 1 car, 1 backpack, 352x640 4 persons, 4 bicycles, 1 car, 3 backpacks, 607.8ms\n",
      "Speed: 0.4ms pre-process, 303.9ms inference, 0.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp347\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets257.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets257.png: 448x640 3 persons, 3 bicycles, 1 car, 1 motorcycle, 448x640 3 persons, 3 bicycles, 2 cars, 1 motorcycle, 688.9ms\n",
      "Speed: 0.5ms pre-process, 344.4ms inference, 0.9ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp348\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets69.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets69.png: 448x640 3 persons, 1 motorcycle, 448x640 3 persons, 1 motorcycle, 677.1ms\n",
      "Speed: 3.5ms pre-process, 338.6ms inference, 1.0ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp349\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets280.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets280.png: 384x640 2 persons, 4 cars, 2 motorcycles, 384x640 3 persons, 4 cars, 2 motorcycles, 600.3ms\n",
      "Speed: 0.5ms pre-process, 300.1ms inference, 1.4ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp350\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets41.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets41.png: 480x640 2 persons, 1 motorcycle, 480x640 2 persons, 1 motorcycle, 804.2ms\n",
      "Speed: 0.4ms pre-process, 402.1ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp351\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets55.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets55.png: 640x480 2 persons, 1 bicycle, 5 cars, 1 traffic light, 640x480 2 persons, 1 bicycle, 4 cars, 1 traffic light, 753.6ms\n",
      "Speed: 0.4ms pre-process, 376.8ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp352\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets294.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets294.png: 320x640 1 person, 1 car, 1 motorcycle, 320x640 1 person, 1 car, 1 motorcycle, 575.3ms\n",
      "Speed: 0.5ms pre-process, 287.7ms inference, 0.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp353\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets727.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets727.png: 448x640 2 persons, 1 motorcycle, 448x640 2 persons, 1 motorcycle, 694.2ms\n",
      "Speed: 0.3ms pre-process, 347.1ms inference, 0.9ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp354\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets733.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets733.png: 448x640 2 persons, 6 motorcycles, 448x640 2 persons, 9 motorcycles, 761.7ms\n",
      "Speed: 0.4ms pre-process, 380.8ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp355\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets109.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets109.png: 640x448 1 person, 1 motorcycle, 640x448 1 person, 1 motorcycle, 885.2ms\n",
      "Speed: 0.5ms pre-process, 442.6ms inference, 0.9ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp356\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets653.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets653.png: 416x640 1 person, 1 motorcycle, 416x640 1 person, 1 motorcycle, 758.4ms\n",
      "Speed: 0.4ms pre-process, 379.2ms inference, 2.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp357\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets135.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets135.png: 640x448 3 persons, 1 motorcycle, 640x448 3 persons, 1 car, 1 motorcycle, 808.8ms\n",
      "Speed: 0.4ms pre-process, 404.4ms inference, 1.1ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp358\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets121.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets121.png: 480x640 1 person, 1 motorcycle, 1 chair, 480x640 1 person, 1 motorcycle, 2 chairs, 834.6ms\n",
      "Speed: 0.2ms pre-process, 417.3ms inference, 1.0ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp359\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets647.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets647.png: 448x640 1 person, 1 bicycle, 3 cars, 1 handbag, 448x640 1 person, 1 bicycle, 2 cars, 1 handbag, 841.2ms\n",
      "Speed: 0.3ms pre-process, 420.6ms inference, 5.1ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp360\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets690.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets690.png: 480x640 5 persons, 1 bicycle, 3 cars, 3 motorcycles, 1 potted plant, 480x640 4 persons, 2 bicycles, 3 cars, 2 motorcycles, 1 potted plant, 826.1ms\n",
      "Speed: 0.4ms pre-process, 413.0ms inference, 1.0ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp361\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets684.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets684.png: 640x448 4 persons, 1 bicycle, 640x448 4 persons, 1 bicycle, 885.4ms\n",
      "Speed: 0.4ms pre-process, 442.7ms inference, 1.2ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp362\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets479.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets479.png: 640x448 1 person, 1 motorcycle, 640x448 1 person, 1 motorcycle, 941.2ms\n",
      "Speed: 0.5ms pre-process, 470.6ms inference, 1.1ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp363\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets337.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets337.png: 640x640 1 person, 1 bicycle, 640x640 1 person, 1 bicycle, 1055.9ms\n",
      "Speed: 0.5ms pre-process, 528.0ms inference, 0.9ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp364\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets451.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets451.png: 448x640 1 person, 1 motorcycle, 448x640 1 person, 1 motorcycle, 713.9ms\n",
      "Speed: 0.4ms pre-process, 356.9ms inference, 0.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp365\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets445.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets445.png: 384x640 1 person, 1 motorcycle, 384x640 1 person, 1 motorcycle, 622.6ms\n",
      "Speed: 0.4ms pre-process, 311.3ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp366\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets323.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets323.png: 480x640 1 person, 1 bicycle, 1 book, 480x640 1 person, 1 bicycle, 1 book, 777.8ms\n",
      "Speed: 0.4ms pre-process, 388.9ms inference, 0.9ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp367\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets492.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets492.png: 608x640 2 persons, 608x640 2 persons, 1 bicycle, 967.5ms\n",
      "Speed: 0.5ms pre-process, 483.7ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp368\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets486.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets486.png: 416x640 9 persons, 4 motorcycles, 1 backpack, 416x640 9 persons, 4 motorcycles, 664.8ms\n",
      "Speed: 0.3ms pre-process, 332.4ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp369\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets487.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets487.png: 448x640 4 persons, 1 motorcycle, 448x640 4 persons, 1 motorcycle, 805.1ms\n",
      "Speed: 0.9ms pre-process, 402.6ms inference, 1.1ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp370\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets493.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets493.png: 480x640 6 persons, 1 car, 2 motorcycles, 1 cow, 480x640 5 persons, 1 car, 2 motorcycles, 1 cow, 802.8ms\n",
      "Speed: 0.3ms pre-process, 401.4ms inference, 1.1ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp371\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets444.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets444.png: 512x640 2 persons, 1 motorcycle, 1 handbag, 512x640 2 persons, 1 motorcycle, 1 handbag, 963.6ms\n",
      "Speed: 0.4ms pre-process, 481.8ms inference, 1.0ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp372\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets322.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets322.png: 512x640 1 person, 1 motorcycle, 512x640 1 person, 1 motorcycle, 950.2ms\n",
      "Speed: 0.5ms pre-process, 475.1ms inference, 1.2ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp373\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets336.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets336.png: 448x640 11 persons, 1 car, 4 motorcycles, 448x640 10 persons, 1 car, 4 motorcycles, 1 backpack, 736.7ms\n",
      "Speed: 0.1ms pre-process, 368.3ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp374\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets450.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets450.png: 416x640 9 persons, 4 motorcycles, 416x640 9 persons, 1 car, 4 motorcycles, 1 bus, 761.2ms\n",
      "Speed: 0.3ms pre-process, 380.6ms inference, 1.1ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp375\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets478.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets478.png: 288x640 4 persons, 2 motorcycles, 288x640 7 persons, 2 motorcycles, 533.6ms\n",
      "Speed: 0.3ms pre-process, 266.8ms inference, 0.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp376\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets685.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets685.png: 480x640 4 persons, 1 car, 2 motorcycles, 1 truck, 480x640 4 persons, 1 bicycle, 1 car, 2 motorcycles, 1 truck, 974.4ms\n",
      "Speed: 1.1ms pre-process, 487.2ms inference, 1.0ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp377\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets691.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets691.png: 448x640 2 persons, 1 motorcycle, 448x640 2 persons, 1 motorcycle, 778.8ms\n",
      "Speed: 0.3ms pre-process, 389.4ms inference, 1.4ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp378\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets120.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets120.png: 384x640 1 person, 1 motorcycle, 384x640 1 person, 1 motorcycle, 528.0ms\n",
      "Speed: 0.3ms pre-process, 264.0ms inference, 0.9ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp379\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets646.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets646.png: 416x640 12 persons, 1 bicycle, 1 motorcycle, 416x640 12 persons, 1 bicycle, 1 motorcycle, 634.1ms\n",
      "Speed: 0.4ms pre-process, 317.0ms inference, 2.3ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp380\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets652.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets652.png: 640x480 2 persons, 2 bicycles, 3 cars, 1 traffic light, 640x480 2 persons, 2 bicycles, 3 cars, 1 traffic light, 744.9ms\n",
      "Speed: 0.4ms pre-process, 372.5ms inference, 1.0ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp381\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets134.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets134.png: 416x640 12 persons, 9 bicycles, 3 cars, 1 truck, 1 traffic light, 416x640 11 persons, 9 bicycles, 3 cars, 1 bus, 1 truck, 2 traffic lights, 643.6ms\n",
      "Speed: 0.4ms pre-process, 321.8ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp382\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets108.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets108.png: 448x640 2 persons, 1 bicycle, 2 cars, 2 motorcycles, 2 traffic lights, 1 handbag, 448x640 2 persons, 1 bicycle, 2 cars, 3 motorcycles, 2 traffic lights, 1 bottle, 682.9ms\n",
      "Speed: 0.4ms pre-process, 341.5ms inference, 1.0ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp383\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets732.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets732.png: 448x640 3 persons, 2 motorcycles, 448x640 2 persons, 3 motorcycles, 785.6ms\n",
      "Speed: 0.4ms pre-process, 392.8ms inference, 1.1ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp384\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets726.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets726.png: 384x640 1 person, 1 motorcycle, 384x640 1 person, 1 motorcycle, 648.4ms\n",
      "Speed: 0.9ms pre-process, 324.2ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp385\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets295.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets295.png: 640x448 3 persons, 1 motorcycle, 640x448 3 persons, 1 car, 1 motorcycle, 888.6ms\n",
      "Speed: 0.4ms pre-process, 444.3ms inference, 1.4ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp386\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets281.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets281.png: 480x640 4 persons, 1 bicycle, 4 cars, 1 truck, 1 traffic light, 480x640 3 persons, 1 bicycle, 4 cars, 1 truck, 1 traffic light, 833.4ms\n",
      "Speed: 0.4ms pre-process, 416.7ms inference, 1.4ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp387\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets40.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets40.png: 640x384 2 persons, 2 bicycles, 640x384 2 persons, 2 bicycles, 591.0ms\n",
      "Speed: 0.4ms pre-process, 295.5ms inference, 2.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp388\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets68.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets68.png: 448x640 3 persons, 1 car, 1 motorcycle, 1 truck, 448x640 2 persons, 1 motorcycle, 1 truck, 693.4ms\n",
      "Speed: 0.4ms pre-process, 346.7ms inference, 1.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp389\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets97.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets97.png: 480x640 8 persons, 5 motorcycles, 480x640 8 persons, 5 motorcycles, 1 backpack, 905.0ms\n",
      "Speed: 0.5ms pre-process, 452.5ms inference, 1.0ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp390\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets530.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets530.png: 448x640 3 persons, 3 bicycles, 1 backpack, 448x640 3 persons, 3 bicycles, 3 backpacks, 744.0ms\n",
      "Speed: 0.4ms pre-process, 372.0ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp391\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets256.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets256.png: 384x640 7 persons, 2 bicycles, 3 motorcycles, 384x640 7 persons, 6 motorcycles, 616.8ms\n",
      "Speed: 1.2ms pre-process, 308.4ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp392\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets242.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets242.png: 448x640 5 persons, 3 cars, 9 motorcycles, 448x640 8 persons, 3 cars, 8 motorcycles, 704.4ms\n",
      "Speed: 0.2ms pre-process, 352.2ms inference, 1.1ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp393\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets83.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets83.png: 448x640 8 persons, 3 cars, 1 motorcycle, 448x640 8 persons, 3 cars, 1 motorcycle, 1 backpack, 719.0ms\n",
      "Speed: 0.5ms pre-process, 359.5ms inference, 0.9ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp394\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets524.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets524.png: 384x640 2 persons, 1 motorcycle, 384x640 2 persons, 1 motorcycle, 588.8ms\n",
      "Speed: 0.3ms pre-process, 294.4ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp395\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets518.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets518.png: 448x640 4 persons, 4 bicycles, 448x640 4 persons, 4 bicycles, 659.3ms\n",
      "Speed: 0.4ms pre-process, 329.6ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp396\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets268.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets268.png: 448x640 1 person, 1 motorcycle, 448x640 1 person, 1 motorcycle, 734.4ms\n",
      "Speed: 0.4ms pre-process, 367.2ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp397\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets254.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets254.png: 640x640 4 persons, 1 bicycle, 640x640 4 persons, 2 bicycles, 1156.7ms\n",
      "Speed: 0.5ms pre-process, 578.3ms inference, 2.0ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp398\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets95.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets95.png: 640x640 2 persons, 2 bicycles, 640x640 2 persons, 2 bicycles, 1 backpack, 982.3ms\n",
      "Speed: 0.6ms pre-process, 491.2ms inference, 1.4ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp399\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets532.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets532.png: 640x448 1 person, 1 bicycle, 1 baseball glove, 640x448 1 person, 1 bicycle, 691.2ms\n",
      "Speed: 0.4ms pre-process, 345.6ms inference, 0.9ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp400\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets81.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets81.png: 640x384 2 persons, 2 bicycles, 640x384 2 persons, 2 bicycles, 602.7ms\n",
      "Speed: 0.3ms pre-process, 301.4ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp401\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets526.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets526.png: 640x576 3 persons, 3 bicycles, 1 car, 2 backpacks, 640x576 3 persons, 3 bicycles, 1 car, 1 backpack, 797.8ms\n",
      "Speed: 0.6ms pre-process, 398.9ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp402\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets240.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets240.png: 480x640 1 person, 1 bicycle, 480x640 1 person, 1 bicycle, 790.5ms\n",
      "Speed: 1.9ms pre-process, 395.2ms inference, 1.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp403\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets297.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets297.png: 448x640 11 persons, 10 bicycles, 3 cars, 3 traffic lights, 1 backpack, 448x640 11 persons, 9 bicycles, 4 cars, 3 traffic lights, 4 backpacks, 691.3ms\n",
      "Speed: 0.5ms pre-process, 345.7ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp404\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets56.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets56.png: 448x640 2 persons, 2 bicycles, 448x640 2 persons, 2 bicycles, 716.8ms\n",
      "Speed: 0.2ms pre-process, 358.4ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp405\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets42.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets42.png: 544x640 1 person, 1 motorcycle, 544x640 1 person, 1 motorcycle, 792.2ms\n",
      "Speed: 0.4ms pre-process, 396.1ms inference, 1.0ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp406\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets283.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets283.png: 384x640 6 persons, 5 cars, 2 motorcycles, 384x640 5 persons, 6 cars, 3 motorcycles, 712.7ms\n",
      "Speed: 0.3ms pre-process, 356.4ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp407\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets718.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets718.png: 352x640 2 persons, 1 bicycle, 10 cars, 1 truck, 3 backpacks, 352x640 2 persons, 2 bicycles, 10 cars, 2 backpacks, 607.8ms\n",
      "Speed: 0.2ms pre-process, 303.9ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp408\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets730.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets730.png: 640x640 1 person, 1 bicycle, 640x640 1 person, 2 bicycles, 1 handbag, 1054.8ms\n",
      "Speed: 2.9ms pre-process, 527.4ms inference, 1.2ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp409\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets724.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets724.png: 384x640 3 persons, 4 cars, 3 motorcycles, 3 trucks, 1 fire hydrant, 384x640 3 persons, 3 cars, 5 motorcycles, 2 trucks, 1 fire hydrant, 1 handbag, 539.4ms\n",
      "Speed: 0.3ms pre-process, 269.7ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp410\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets678.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets678.png: 512x640 1 person, 1 motorcycle, 1 bus, 1 cell phone, 512x640 1 person, 1 motorcycle, 1 bus, 2 trucks, 1 cell phone, 702.6ms\n",
      "Speed: 0.4ms pre-process, 351.3ms inference, 0.9ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp411\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets644.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets644.png: 416x640 3 persons, 3 bicycles, 416x640 3 persons, 3 bicycles, 546.7ms\n",
      "Speed: 0.2ms pre-process, 273.3ms inference, 0.5ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp412\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets122.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets122.png: 480x640 1 person, 1 motorcycle, 480x640 1 person, 1 motorcycle, 662.1ms\n",
      "Speed: 0.3ms pre-process, 331.0ms inference, 0.9ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp413\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets136.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets136.png: 320x640 2 persons, 1 bicycle, 4 potted plants, 320x640 2 persons, 1 bicycle, 5 potted plants, 478.6ms\n",
      "Speed: 0.2ms pre-process, 239.3ms inference, 1.2ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp414\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets650.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets650.png: 480x640 1 person, 1 motorcycle, 480x640 1 person, 1 motorcycle, 790.7ms\n",
      "Speed: 0.4ms pre-process, 395.4ms inference, 1.4ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp415\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets687.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets687.png: 384x640 1 person, 1 bicycle, 2 cars, 384x640 1 person, 1 bicycle, 2 cars, 578.1ms\n",
      "Speed: 0.4ms pre-process, 289.0ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp416\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets693.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets693.png: 448x640 2 persons, 448x640 2 persons, 582.6ms\n",
      "Speed: 0.5ms pre-process, 291.3ms inference, 0.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp417\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets308.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets308.png: 416x640 4 persons, 4 bicycles, 416x640 5 persons, 4 bicycles, 1 stop sign, 555.4ms\n",
      "Speed: 0.2ms pre-process, 277.7ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp418\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets320.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets320.png: 448x640 4 persons, 4 bicycles, 1 cow, 1 backpack, 448x640 4 persons, 4 bicycles, 1 cow, 1 backpack, 627.2ms\n",
      "Speed: 0.5ms pre-process, 313.6ms inference, 0.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp419\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets446.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets446.png: 416x640 3 persons, 3 bicycles, 1 car, 416x640 3 persons, 3 bicycles, 1 car, 1 truck, 609.6ms\n",
      "Speed: 0.3ms pre-process, 304.8ms inference, 0.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp420\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets452.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets452.png: 512x640 1 person, 1 bicycle, 512x640 1 person, 1 bicycle, 784.8ms\n",
      "Speed: 0.4ms pre-process, 392.4ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp421\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets334.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets334.png: 480x640 17 persons, 12 bicycles, 1 suitcase, 480x640 18 persons, 13 bicycles, 2 handbags, 728.3ms\n",
      "Speed: 0.4ms pre-process, 364.1ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp422\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets485.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets485.png: 640x640 1 person, 1 cell phone, 640x640 1 person, 1 cell phone, 865.3ms\n",
      "Speed: 1.0ms pre-process, 432.7ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp423\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets491.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets491.png: 384x640 2 persons, 2 cars, 1 motorcycle, 1 handbag, 384x640 2 persons, 2 cars, 2 motorcycles, 1 handbag, 621.7ms\n",
      "Speed: 0.6ms pre-process, 310.8ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp424\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets490.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets490.png: 640x640 1 person, 1 bicycle, 640x640 1 person, 840.9ms\n",
      "Speed: 0.5ms pre-process, 420.5ms inference, 1.3ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp425\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets484.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets484.png: 608x640 3 persons, 2 bicycles, 4 cars, 608x640 3 persons, 2 bicycles, 5 cars, 795.9ms\n",
      "Speed: 0.5ms pre-process, 398.0ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp426\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets453.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets453.png: 640x480 4 persons, 3 cars, 1 motorcycle, 640x480 4 persons, 3 cars, 1 motorcycle, 693.1ms\n",
      "Speed: 0.4ms pre-process, 346.6ms inference, 1.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp427\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets335.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets335.png: 640x480 3 persons, 5 motorcycles, 640x480 3 persons, 6 motorcycles, 587.6ms\n",
      "Speed: 0.6ms pre-process, 293.8ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp428\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets321.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets321.png: 448x640 3 persons, 3 bicycles, 448x640 3 persons, 3 bicycles, 614.4ms\n",
      "Speed: 0.4ms pre-process, 307.2ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp429\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets447.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets447.png: 544x640 1 person, 1 motorcycle, 544x640 1 person, 1 motorcycle, 703.1ms\n",
      "Speed: 1.4ms pre-process, 351.6ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp430\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets309.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets309.png: 640x576 1 person, 1 motorcycle, 640x576 1 person, 1 bicycle, 741.6ms\n",
      "Speed: 0.4ms pre-process, 370.8ms inference, 0.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp431\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets692.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets692.png: 480x640 4 persons, 4 bicycles, 480x640 4 persons, 4 bicycles, 650.2ms\n",
      "Speed: 0.3ms pre-process, 325.1ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp432\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets686.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets686.png: 352x640 4 persons, 1 motorcycle, 352x640 4 persons, 3 bicycles, 1 dog, 2 backpacks, 451.5ms\n",
      "Speed: 0.3ms pre-process, 225.8ms inference, 0.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp433\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets137.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets137.png: 416x640 8 persons, 8 motorcycles, 416x640 8 persons, 8 motorcycles, 641.6ms\n",
      "Speed: 0.3ms pre-process, 320.8ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp434\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets651.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets651.png: 384x640 4 persons, 1 bicycle, 1 car, 2 motorcycles, 384x640 4 persons, 1 bicycle, 1 car, 1 motorcycle, 1 handbag, 551.1ms\n",
      "Speed: 0.3ms pre-process, 275.5ms inference, 0.9ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp435\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets645.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets645.png: 480x640 6 persons, 1 car, 4 motorcycles, 480x640 6 persons, 2 cars, 4 motorcycles, 787.4ms\n",
      "Speed: 0.5ms pre-process, 393.7ms inference, 1.0ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp436\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets123.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets123.png: 448x640 4 persons, 1 bicycle, 448x640 4 persons, 1 bicycle, 606.2ms\n",
      "Speed: 0.4ms pre-process, 303.1ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp437\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets679.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets679.png: 384x640 2 persons, 1 bicycle, 5 cars, 384x640 2 persons, 1 bicycle, 5 cars, 505.3ms\n",
      "Speed: 0.2ms pre-process, 252.7ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp438\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets725.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets725.png: 416x640 5 persons, 5 motorcycles, 416x640 5 persons, 5 motorcycles, 795.3ms\n",
      "Speed: 0.2ms pre-process, 397.7ms inference, 1.0ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp439\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets731.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets731.png: 544x640 7 persons, 1 bicycle, 544x640 7 persons, 1 bicycle, 843.4ms\n",
      "Speed: 0.6ms pre-process, 421.7ms inference, 1.0ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp440\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets719.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets719.png: 608x640 2 persons, 2 cars, 3 motorcycles, 2 trucks, 608x640 2 persons, 2 cars, 3 motorcycles, 2 trucks, 852.3ms\n",
      "Speed: 0.7ms pre-process, 426.2ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp441\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets43.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets43.png: 480x640 4 persons, 1 bicycle, 480x640 5 persons, 1 bicycle, 1 backpack, 726.4ms\n",
      "Speed: 0.3ms pre-process, 363.2ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp442\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets282.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets282.png: 640x576 2 persons, 1 motorcycle, 640x576 2 persons, 1 motorcycle, 858.4ms\n",
      "Speed: 0.5ms pre-process, 429.2ms inference, 0.9ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp443\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets296.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets296.png: 480x640 2 persons, 2 cars, 1 motorcycle, 1 potted plant, 480x640 3 persons, 1 car, 1 motorcycle, 1 cup, 2 potted plants, 725.1ms\n",
      "Speed: 0.4ms pre-process, 362.5ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp444\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets57.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets57.png: 384x640 5 persons, 1 car, 2 motorcycles, 1 bus, 2 backpacks, 384x640 7 persons, 1 car, 1 motorcycle, 1 bus, 1 backpack, 719.0ms\n",
      "Speed: 0.3ms pre-process, 359.5ms inference, 1.1ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp445\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets527.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets527.png: 352x640 5 persons, 2 motorcycles, 352x640 4 persons, 2 motorcycles, 483.3ms\n",
      "Speed: 0.1ms pre-process, 241.6ms inference, 0.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp446\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets80.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets80.png: 384x640 7 persons, 2 cars, 4 motorcycles, 384x640 5 persons, 3 cars, 4 motorcycles, 528.3ms\n",
      "Speed: 0.3ms pre-process, 264.1ms inference, 0.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp447\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets241.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets241.png: 448x640 1 person, 1 bicycle, 2 benchs, 448x640 1 person, 1 bicycle, 2 benchs, 638.8ms\n",
      "Speed: 0.4ms pre-process, 319.4ms inference, 0.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp448\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets255.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets255.png: 448x640 3 persons, 2 bicycles, 2 benchs, 448x640 3 persons, 2 bicycles, 1 bench, 1 handbag, 631.7ms\n",
      "Speed: 0.7ms pre-process, 315.8ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp449\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets533.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets533.png: 448x640 1 person, 1 motorcycle, 448x640 1 person, 1 motorcycle, 627.8ms\n",
      "Speed: 0.4ms pre-process, 313.9ms inference, 0.5ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp450\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets94.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets94.png: 480x640 1 person, 1 motorcycle, 480x640 1 person, 1 motorcycle, 676.1ms\n",
      "Speed: 0.5ms pre-process, 338.0ms inference, 0.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp451\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets269.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets269.png: 448x640 1 person, 1 bicycle, 448x640 1 person, 1 bicycle, 693.0ms\n",
      "Speed: 1.3ms pre-process, 346.5ms inference, 1.4ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp452\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets90.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets90.png: 448x640 1 person, 1 motorcycle, 1 backpack, 448x640 1 person, 1 motorcycle, 1 backpack, 588.9ms\n",
      "Speed: 0.4ms pre-process, 294.5ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp453\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets537.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets537.png: 448x640 2 persons, 2 motorcycles, 448x640 1 person, 2 motorcycles, 585.6ms\n",
      "Speed: 0.4ms pre-process, 292.8ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp454\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets251.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets251.png: 384x640 1 person, 2 motorcycles, 1 potted plant, 384x640 1 person, 2 motorcycles, 2 potted plants, 498.6ms\n",
      "Speed: 0.3ms pre-process, 249.3ms inference, 0.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp455\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets245.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets245.png: 640x640 7 persons, 1 car, 1 motorcycle, 1 traffic light, 1 handbag, 640x640 8 persons, 1 car, 1 motorcycle, 1 traffic light, 1 handbag, 895.9ms\n",
      "Speed: 0.5ms pre-process, 447.9ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp456\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets84.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets84.png: 640x640 1 person, 1 bicycle, 640x640 1 person, 1 bicycle, 1118.3ms\n",
      "Speed: 0.2ms pre-process, 559.1ms inference, 1.5ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp457\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets523.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets523.png: 480x640 5 persons, 2 bicycles, 3 cars, 2 backpacks, 1 handbag, 480x640 5 persons, 2 bicycles, 2 cars, 2 backpacks, 660.4ms\n",
      "Speed: 0.6ms pre-process, 330.2ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp458\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets279.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets279.png: 640x640 2 persons, 2 chairs, 640x640 1 person, 1 bicycle, 811.1ms\n",
      "Speed: 0.5ms pre-process, 405.5ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp459\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets53.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets53.png: 448x640 1 person, 1 motorcycle, 448x640 1 person, 1 motorcycle, 556.1ms\n",
      "Speed: 0.4ms pre-process, 278.0ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp460\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets292.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets292.png: 480x640 1 person, 1 motorcycle, 480x640 1 person, 1 motorcycle, 649.0ms\n",
      "Speed: 0.4ms pre-process, 324.5ms inference, 0.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp461\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets286.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets286.png: 256x640 3 persons, 2 bicycles, 1 car, 3 trucks, 1 backpack, 256x640 3 persons, 2 bicycles, 3 cars, 3 trucks, 3 backpacks, 1 suitcase, 370.6ms\n",
      "Speed: 0.2ms pre-process, 185.3ms inference, 0.5ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp462\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets47.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets47.png: 448x640 6 persons, 3 motorcycles, 448x640 6 persons, 3 motorcycles, 567.2ms\n",
      "Speed: 0.2ms pre-process, 283.6ms inference, 0.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp463\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets735.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets735.png: 448x640 6 persons, 2 cars, 5 motorcycles, 448x640 7 persons, 3 cars, 6 motorcycles, 632.9ms\n",
      "Speed: 0.4ms pre-process, 316.4ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp464\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets721.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets721.png: 480x640 1 person, 1 motorcycle, 480x640 1 person, 1 motorcycle, 662.1ms\n",
      "Speed: 0.4ms pre-process, 331.0ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp465\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets709.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets709.png: 448x640 1 person, 3 motorcycles, 1 handbag, 448x640 1 person, 4 motorcycles, 1 handbag, 625.5ms\n",
      "Speed: 0.3ms pre-process, 312.7ms inference, 10.3ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp466\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets127.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets127.png: 640x416 1 person, 640x416 1 person, 1 bicycle, 1 umbrella, 546.4ms\n",
      "Speed: 0.4ms pre-process, 273.2ms inference, 0.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp467\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets641.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets641.png: 480x640 3 persons, 1 bicycle, 1 dog, 1 potted plant, 1 teddy bear, 480x640 2 persons, 1 bicycle, 1 dog, 1 potted plant, 661.6ms\n",
      "Speed: 0.3ms pre-process, 330.8ms inference, 0.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp468\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets655.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets655.png: 384x640 1 person, 1 motorcycle, 384x640 1 person, 1 motorcycle, 678.2ms\n",
      "Speed: 0.3ms pre-process, 339.1ms inference, 1.0ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp469\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets133.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets133.png: 448x640 14 persons, 1 motorcycle, 1 truck, 448x640 13 persons, 1 motorcycle, 1 truck, 642.4ms\n",
      "Speed: 0.3ms pre-process, 321.2ms inference, 1.1ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp470\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets669.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets669.png: 384x640 1 person, 1 motorcycle, 384x640 1 person, 1 motorcycle, 641.3ms\n",
      "Speed: 0.3ms pre-process, 320.6ms inference, 0.9ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp471\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets682.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets682.png: 224x640 6 persons, 3 bicycles, 1 bench, 2 backpacks, 224x640 6 persons, 3 bicycles, 1 bench, 2 backpacks, 289.0ms\n",
      "Speed: 0.2ms pre-process, 144.5ms inference, 0.5ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp472\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets696.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets696.png: 512x640 2 persons, 1 car, 1 motorcycle, 1 potted plant, 512x640 2 persons, 1 car, 1 motorcycle, 1 potted plant, 936.8ms\n",
      "Speed: 0.5ms pre-process, 468.4ms inference, 3.1ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp473\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets443.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets443.png: 448x640 5 persons, 5 bicycles, 448x640 5 persons, 5 bicycles, 575.6ms\n",
      "Speed: 0.4ms pre-process, 287.8ms inference, 0.9ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp474\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets325.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets325.png: 416x640 16 persons, 12 bicycles, 1 car, 1 truck, 3 traffic lights, 3 backpacks, 416x640 14 persons, 12 bicycles, 2 cars, 1 truck, 6 traffic lights, 4 backpacks, 608.4ms\n",
      "Speed: 0.3ms pre-process, 304.2ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp475\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets331.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets331.png: 448x640 4 persons, 1 car, 1 motorcycle, 1 truck, 448x640 5 persons, 1 car, 1 motorcycle, 1 truck, 591.4ms\n",
      "Speed: 0.4ms pre-process, 295.7ms inference, 0.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp476\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets457.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets457.png: 448x640 8 persons, 2 bicycles, 4 cars, 2 traffic lights, 1 backpack, 1 handbag, 448x640 9 persons, 2 bicycles, 4 cars, 2 traffic lights, 2 backpacks, 1 handbag, 586.9ms\n",
      "Speed: 1.3ms pre-process, 293.4ms inference, 0.9ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp477\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets319.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets319.png: 448x640 2 persons, 4 cars, 3 motorcycles, 1 backpack, 448x640 2 persons, 5 cars, 3 motorcycles, 1 backpack, 555.5ms\n",
      "Speed: 0.4ms pre-process, 277.7ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp478\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets480.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets480.png: 448x640 10 persons, 1 bicycle, 1 handbag, 1 tie, 6 chairs, 448x640 13 persons, 1 bicycle, 1 tie, 9 chairs, 1 dining table, 666.7ms\n",
      "Speed: 0.4ms pre-process, 333.3ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp479\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets494.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets494.png: 640x640 5 persons, 2 motorcycles, 640x640 6 persons, 2 motorcycles, 864.5ms\n",
      "Speed: 0.6ms pre-process, 432.2ms inference, 1.3ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp480\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets495.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets495.png: 384x640 2 persons, 2 bicycles, 3 bottles, 384x640 2 persons, 2 bicycles, 2 bottles, 521.7ms\n",
      "Speed: 0.3ms pre-process, 260.8ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp481\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets481.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets481.png: 512x640 2 persons, 4 cars, 1 motorcycle, 512x640 2 persons, 4 cars, 1 motorcycle, 809.1ms\n",
      "Speed: 0.4ms pre-process, 404.6ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp482\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets318.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets318.png: 640x640 3 persons, 2 motorcycles, 640x640 2 persons, 2 motorcycles, 865.5ms\n",
      "Speed: 0.6ms pre-process, 432.8ms inference, 1.1ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp483\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets330.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets330.png: 544x640 1 person, 1 car, 1 motorcycle, 1 truck, 1 handbag, 544x640 1 person, 1 car, 1 motorcycle, 1 truck, 2 handbags, 752.2ms\n",
      "Speed: 0.5ms pre-process, 376.1ms inference, 1.2ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp484\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets456.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets456.png: 640x448 2 persons, 1 motorcycle, 1 handbag, 640x448 2 persons, 1 motorcycle, 1 handbag, 622.4ms\n",
      "Speed: 0.3ms pre-process, 311.2ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp485\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets442.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets442.png: 544x640 13 persons, 7 bicycles, 3 traffic lights, 2 backpacks, 1 frisbee, 544x640 12 persons, 7 bicycles, 3 traffic lights, 3 backpacks, 788.9ms\n",
      "Speed: 0.4ms pre-process, 394.5ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp486\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets324.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets324.png: 480x640 1 person, 2 cars, 1 motorcycle, 480x640 2 persons, 1 motorcycle, 1 suitcase, 1 bottle, 646.5ms\n",
      "Speed: 0.5ms pre-process, 323.2ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp487\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets697.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets697.png: 448x640 9 persons, 10 motorcycles, 448x640 9 persons, 12 motorcycles, 610.6ms\n",
      "Speed: 0.8ms pre-process, 305.3ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp488\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets683.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets683.png: 384x640 7 persons, 3 cars, 3 motorcycles, 384x640 9 persons, 3 cars, 3 motorcycles, 565.5ms\n",
      "Speed: 0.4ms pre-process, 282.7ms inference, 0.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp489\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets668.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets668.png: 384x640 5 persons, 3 motorcycles, 1 dog, 384x640 5 persons, 3 motorcycles, 508.7ms\n",
      "Speed: 0.4ms pre-process, 254.3ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp490\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets654.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets654.png: 512x640 1 person, 1 bicycle, 1 backpack, 512x640 1 person, 1 bicycle, 1 backpack, 710.6ms\n",
      "Speed: 0.4ms pre-process, 355.3ms inference, 0.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp491\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets132.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets132.png: 448x640 9 persons, 7 bicycles, 448x640 10 persons, 7 bicycles, 590.5ms\n",
      "Speed: 0.4ms pre-process, 295.3ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp492\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets126.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets126.png: 448x640 20 persons, 1 car, 4 motorcycles, 1 chair, 448x640 18 persons, 2 cars, 4 motorcycles, 1 chair, 757.2ms\n",
      "Speed: 0.5ms pre-process, 378.6ms inference, 0.9ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp493\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets640.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets640.png: 448x640 11 persons, 4 bicycles, 3 buss, 1 truck, 1 handbag, 448x640 15 persons, 8 bicycles, 3 cars, 3 buss, 2 trucks, 1 handbag, 663.9ms\n",
      "Speed: 8.5ms pre-process, 331.9ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp494\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets708.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets708.png: 480x640 8 persons, 6 bicycles, 1 backpack, 480x640 8 persons, 7 bicycles, 2 cars, 667.6ms\n",
      "Speed: 0.4ms pre-process, 333.8ms inference, 0.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp495\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets720.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets720.png: 480x640 6 persons, 3 bicycles, 5 cars, 2 buss, 480x640 6 persons, 3 bicycles, 5 cars, 2 buss, 742.9ms\n",
      "Speed: 0.4ms pre-process, 371.4ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp496\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets734.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets734.png: 416x640 1 person, 1 motorcycle, 1 backpack, 1 kite, 416x640 1 person, 1 motorcycle, 1 backpack, 1 kite, 610.9ms\n",
      "Speed: 0.4ms pre-process, 305.5ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp497\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets287.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets287.png: 640x640 4 persons, 2 bicycles, 1 car, 640x640 4 persons, 2 bicycles, 2 cars, 803.6ms\n",
      "Speed: 0.6ms pre-process, 401.8ms inference, 1.0ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp498\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets46.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets46.png: 448x640 1 person, 1 motorcycle, 448x640 1 person, 1 motorcycle, 614.5ms\n",
      "Speed: 0.5ms pre-process, 307.3ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp499\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets52.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets52.png: 448x640 4 persons, 3 bicycles, 1 car, 3 handbags, 448x640 4 persons, 3 bicycles, 1 car, 2 handbags, 630.6ms\n",
      "Speed: 0.4ms pre-process, 315.3ms inference, 4.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp500\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets293.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets293.png: 480x640 15 persons, 8 bicycles, 1 backpack, 1 umbrella, 1 handbag, 480x640 17 persons, 11 bicycles, 1 car, 1 backpack, 2 umbrellas, 2 handbags, 653.6ms\n",
      "Speed: 0.5ms pre-process, 326.8ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp501\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets278.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets278.png: 448x640 1 person, 1 bicycle, 2 cars, 1 motorcycle, 1 backpack, 1 chair, 448x640 1 person, 1 bicycle, 1 car, 1 backpack, 1 chair, 573.4ms\n",
      "Speed: 0.4ms pre-process, 286.7ms inference, 0.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp502\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets244.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets244.png: 224x640 5 persons, 3 bicycles, 3 cars, 1 truck, 2 backpacks, 224x640 5 persons, 4 bicycles, 3 cars, 1 truck, 2 backpacks, 328.0ms\n",
      "Speed: 0.2ms pre-process, 164.0ms inference, 0.9ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp503\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets522.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets522.png: 448x640 1 person, 3 cars, 1 motorcycle, 448x640 1 person, 3 cars, 1 motorcycle, 642.1ms\n",
      "Speed: 0.4ms pre-process, 321.1ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp504\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets85.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets85.png: 448x640 1 person, 1 frisbee, 448x640 1 person, 596.0ms\n",
      "Speed: 0.4ms pre-process, 298.0ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp505\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets536.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets536.png: 384x640 2 persons, 3 bicycles, 384x640 2 persons, 3 bicycles, 529.1ms\n",
      "Speed: 0.3ms pre-process, 264.5ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp506\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets91.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets91.png: 320x640 10 persons, 7 motorcycles, 320x640 10 persons, 8 motorcycles, 415.4ms\n",
      "Speed: 0.3ms pre-process, 207.7ms inference, 0.5ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp507\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets250.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets250.png: 480x640 2 persons, 3 bicycles, 3 backpacks, 480x640 3 persons, 2 bicycles, 2 backpacks, 1 handbag, 640.6ms\n",
      "Speed: 0.4ms pre-process, 320.3ms inference, 0.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp508\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets520.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets520.png: 352x640 13 persons, 1 car, 7 motorcycles, 1 traffic light, 1 backpack, 352x640 13 persons, 1 car, 5 motorcycles, 1 traffic light, 469.5ms\n",
      "Speed: 0.3ms pre-process, 234.7ms inference, 0.5ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp509\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets87.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets87.png: 448x640 8 persons, 4 bicycles, 4 backpacks, 1 umbrella, 448x640 14 persons, 4 bicycles, 5 backpacks, 599.3ms\n",
      "Speed: 0.4ms pre-process, 299.6ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp510\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets246.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets246.png: 384x640 1 person, 1 car, 1 motorcycle, 384x640 1 person, 1 car, 1 motorcycle, 497.1ms\n",
      "Speed: 0.4ms pre-process, 248.6ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp511\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets252.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets252.png: 448x640 2 persons, 448x640 2 persons, 601.8ms\n",
      "Speed: 0.4ms pre-process, 300.9ms inference, 1.3ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp512\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets534.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets534.png: 576x640 1 person, 1 bicycle, 576x640 1 person, 1 bicycle, 769.0ms\n",
      "Speed: 0.4ms pre-process, 384.5ms inference, 1.0ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp513\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets93.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets93.png: 448x640 5 persons, 3 motorcycles, 448x640 4 persons, 3 motorcycles, 605.2ms\n",
      "Speed: 1.0ms pre-process, 302.6ms inference, 0.9ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp514\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets508.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets508.png: 384x640 1 person, 1 motorcycle, 2 cows, 1 backpack, 384x640 1 person, 1 motorcycle, 1 cow, 1 backpack, 1 bottle, 517.2ms\n",
      "Speed: 0.4ms pre-process, 258.6ms inference, 0.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp515\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets44.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets44.png: 512x640 9 persons, 5 motorcycles, 1 truck, 512x640 10 persons, 5 motorcycles, 2 trucks, 728.4ms\n",
      "Speed: 0.3ms pre-process, 364.2ms inference, 1.4ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp516\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets285.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets285.png: 640x448 2 persons, 1 motorcycle, 640x448 2 persons, 1 motorcycle, 603.7ms\n",
      "Speed: 0.4ms pre-process, 301.8ms inference, 4.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp517\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets291.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets291.png: 448x640 1 person, 1 motorcycle, 448x640 1 person, 1 motorcycle, 551.9ms\n",
      "Speed: 0.4ms pre-process, 275.9ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp518\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets78.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets78.png: 640x480 2 persons, 1 bicycle, 3 motorcycles, 640x480 3 persons, 4 motorcycles, 1 scissors, 689.2ms\n",
      "Speed: 0.4ms pre-process, 344.6ms inference, 1.4ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp519\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets722.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets722.png: 640x448 1 person, 1 bicycle, 1 handbag, 640x448 1 person, 1 bicycle, 1 handbag, 574.6ms\n",
      "Speed: 0.4ms pre-process, 287.3ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp520\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets736.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets736.png: 416x640 4 persons, 1 car, 2 motorcycles, 1 bus, 2 backpacks, 416x640 4 persons, 1 car, 1 motorcycle, 2 buss, 1 backpack, 598.9ms\n",
      "Speed: 0.4ms pre-process, 299.5ms inference, 0.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp521\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets130.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets130.png: 448x640 1 person, 1 bicycle, 3 cars, 1 motorcycle, 448x640 1 person, 1 bicycle, 3 cars, 2 motorcycles, 616.1ms\n",
      "Speed: 0.4ms pre-process, 308.0ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp522\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets656.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets656.png: 640x512 3 persons, 1 motorcycle, 1 truck, 640x512 2 persons, 1 motorcycle, 1 truck, 747.7ms\n",
      "Speed: 0.5ms pre-process, 373.8ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp523\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets642.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets642.png: 448x640 5 persons, 2 cars, 2 motorcycles, 448x640 5 persons, 2 cars, 2 motorcycles, 599.0ms\n",
      "Speed: 0.6ms pre-process, 299.5ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp524\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets124.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets124.png: 480x640 7 persons, 6 bicycles, 5 cars, 1 handbag, 480x640 7 persons, 6 bicycles, 5 cars, 726.7ms\n",
      "Speed: 2.1ms pre-process, 363.3ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp525\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets118.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets118.png: 576x640 1 person, 1 bicycle, 576x640 1 person, 1 bicycle, 785.9ms\n",
      "Speed: 0.6ms pre-process, 393.0ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp526\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets695.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets695.png: 448x640 2 persons, 1 motorcycle, 448x640 2 persons, 1 motorcycle, 573.6ms\n",
      "Speed: 0.3ms pre-process, 286.8ms inference, 0.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp527\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets681.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets681.png: 416x640 4 persons, 1 car, 2 motorcycles, 1 bus, 2 backpacks, 416x640 4 persons, 1 car, 1 motorcycle, 2 buss, 1 backpack, 580.1ms\n",
      "Speed: 0.4ms pre-process, 290.1ms inference, 0.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp528\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets454.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets454.png: 448x640 10 persons, 9 bicycles, 1 backpack, 448x640 10 persons, 9 bicycles, 1 backpack, 576.9ms\n",
      "Speed: 0.4ms pre-process, 288.4ms inference, 1.2ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp529\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets332.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets332.png: 448x640 7 persons, 5 bicycles, 448x640 7 persons, 5 bicycles, 653.8ms\n",
      "Speed: 0.4ms pre-process, 326.9ms inference, 0.9ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp530\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets326.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets326.png: 640x480 2 persons, 2 cars, 1 motorcycle, 640x480 1 person, 3 cars, 1 motorcycle, 736.3ms\n",
      "Speed: 0.4ms pre-process, 368.2ms inference, 0.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp531\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets440.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets440.png: 448x640 10 persons, 5 motorcycles, 448x640 11 persons, 6 motorcycles, 599.4ms\n",
      "Speed: 0.6ms pre-process, 299.7ms inference, 1.2ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp532\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets468.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets468.png: 640x640 1 person, 1 motorcycle, 640x640 1 person, 1 motorcycle, 947.6ms\n",
      "Speed: 0.6ms pre-process, 473.8ms inference, 1.9ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp533\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets497.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets497.png: 384x640 4 persons, 1 bicycle, 1 backpack, 384x640 4 persons, 1 bicycle, 1 backpack, 539.1ms\n",
      "Speed: 0.3ms pre-process, 269.6ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp534\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets483.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets483.png: 640x640 10 persons, 1 bicycle, 6 motorcycles, 1 truck, 1 traffic light, 640x640 9 persons, 1 bicycle, 1 car, 5 motorcycles, 1 traffic light, 936.3ms\n",
      "Speed: 0.7ms pre-process, 468.1ms inference, 1.1ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp535\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets482.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets482.png: 384x640 1 person, 1 bicycle, 6 cars, 1 traffic light, 384x640 3 persons, 1 bicycle, 6 cars, 1 traffic light, 539.4ms\n",
      "Speed: 0.3ms pre-process, 269.7ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp536\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets496.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets496.png: 480x640 2 persons, 1 car, 1 motorcycle, 1 potted plant, 480x640 3 persons, 1 car, 1 motorcycle, 1 cup, 2 potted plants, 605.4ms\n",
      "Speed: 0.5ms pre-process, 302.7ms inference, 0.9ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp537\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets469.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets469.png: 576x640 8 persons, 5 motorcycles, 576x640 8 persons, 5 motorcycles, 760.4ms\n",
      "Speed: 0.4ms pre-process, 380.2ms inference, 1.4ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp538\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets327.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets327.png: 448x640 5 persons, 1 motorcycle, 1 umbrella, 448x640 4 persons, 1 motorcycle, 1 umbrella, 603.9ms\n",
      "Speed: 0.4ms pre-process, 301.9ms inference, 1.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp539\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets441.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets441.png: 480x640 1 person, 1 motorcycle, 480x640 1 person, 1 motorcycle, 749.3ms\n",
      "Speed: 0.4ms pre-process, 374.6ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp540\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets455.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets455.png: 448x640 1 person, 1 motorcycle, 448x640 1 person, 1 motorcycle, 609.9ms\n",
      "Speed: 0.4ms pre-process, 304.9ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp541\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets333.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets333.png: 448x640 2 persons, 448x640 2 persons, 642.4ms\n",
      "Speed: 0.3ms pre-process, 321.2ms inference, 0.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp542\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets680.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets680.png: 640x480 1 person, 640x480 1 person, 1 bowl, 742.4ms\n",
      "Speed: 0.4ms pre-process, 371.2ms inference, 0.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp543\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets694.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets694.png: 448x640 1 person, 1 motorcycle, 2 potted plants, 448x640 1 person, 1 motorcycle, 3 potted plants, 716.7ms\n",
      "Speed: 0.3ms pre-process, 358.4ms inference, 1.3ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp544\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets119.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets119.png: 448x640 7 persons, 1 bicycle, 1 motorcycle, 448x640 6 persons, 1 motorcycle, 637.9ms\n",
      "Speed: 1.2ms pre-process, 319.0ms inference, 0.9ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp545\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets643.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets643.png: 448x640 11 persons, 3 motorcycles, 448x640 13 persons, 2 motorcycles, 627.9ms\n",
      "Speed: 0.3ms pre-process, 314.0ms inference, 1.1ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp546\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets125.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets125.png: 480x640 2 persons, 5 cars, 1 motorcycle, 480x640 2 persons, 4 cars, 1 motorcycle, 646.3ms\n",
      "Speed: 0.4ms pre-process, 323.1ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp547\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets131.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets131.png: 480x640 7 persons, 6 bicycles, 5 cars, 1 handbag, 480x640 7 persons, 6 bicycles, 5 cars, 661.9ms\n",
      "Speed: 0.4ms pre-process, 331.0ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp548\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets657.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets657.png: 416x640 8 persons, 1 bicycle, 1 car, 5 motorcycles, 1 skateboard, 416x640 10 persons, 1 bicycle, 1 car, 5 motorcycles, 1 skateboard, 602.2ms\n",
      "Speed: 0.3ms pre-process, 301.1ms inference, 1.0ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp549\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets737.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets737.png: 416x640 10 persons, 6 bicycles, 416x640 10 persons, 5 bicycles, 690.6ms\n",
      "Speed: 0.3ms pre-process, 345.3ms inference, 1.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp550\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets723.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets723.png: 448x640 1 person, 1 bicycle, 3 cars, 1 motorcycle, 448x640 1 person, 1 bicycle, 2 cars, 1 motorcycle, 590.1ms\n",
      "Speed: 0.6ms pre-process, 295.0ms inference, 0.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp551\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets79.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets79.png: 448x640 6 persons, 3 bicycles, 448x640 6 persons, 3 bicycles, 2 backpacks, 764.0ms\n",
      "Speed: 0.3ms pre-process, 382.0ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp552\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets290.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets290.png: 448x640 2 persons, 1 bicycle, 1 bottle, 448x640 2 persons, 1 bicycle, 1 bottle, 661.0ms\n",
      "Speed: 0.4ms pre-process, 330.5ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp553\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets51.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets51.png: 480x640 1 person, 1 motorcycle, 480x640 1 person, 1 motorcycle, 866.1ms\n",
      "Speed: 0.4ms pre-process, 433.1ms inference, 0.9ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp554\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets45.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets45.png: 448x640 1 person, 1 bicycle, 3 cars, 1 motorcycle, 448x640 1 person, 1 bicycle, 3 cars, 2 motorcycles, 701.5ms\n",
      "Speed: 0.4ms pre-process, 350.7ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp555\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets284.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets284.png: 384x640 4 persons, 1 bicycle, 1 car, 1 motorcycle, 384x640 4 persons, 2 bicycles, 2 cars, 2 motorcycles, 539.2ms\n",
      "Speed: 0.4ms pre-process, 269.6ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp556\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets509.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets509.png: 640x448 3 persons, 4 bicycles, 640x448 2 persons, 4 bicycles, 1 suitcase, 625.3ms\n",
      "Speed: 0.4ms pre-process, 312.7ms inference, 1.3ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp557\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets253.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets253.png: 416x640 2 persons, 2 bicycles, 1 car, 1 truck, 416x640 2 persons, 2 bicycles, 1 car, 1 truck, 597.3ms\n",
      "Speed: 0.4ms pre-process, 298.6ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp558\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets92.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets92.png: 448x640 1 person, 4 cars, 1 motorcycle, 448x640 1 person, 4 cars, 1 motorcycle, 579.1ms\n",
      "Speed: 0.3ms pre-process, 289.6ms inference, 0.9ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp559\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets535.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets535.png: 640x640 1 person, 2 cars, 1 motorcycle, 640x640 1 person, 2 cars, 1 motorcycle, 784.4ms\n",
      "Speed: 0.4ms pre-process, 392.2ms inference, 0.9ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp560\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets86.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets86.png: 640x448 1 person, 2 bicycles, 640x448 1 person, 1 bicycle, 559.3ms\n",
      "Speed: 0.3ms pre-process, 279.7ms inference, 0.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp561\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets521.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets521.png: 384x640 1 person, 1 bicycle, 1 motorcycle, 384x640 1 person, 1 bicycle, 496.1ms\n",
      "Speed: 0.3ms pre-process, 248.0ms inference, 0.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp562\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets247.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets247.png: 448x640 4 persons, 4 bicycles, 448x640 4 persons, 4 bicycles, 615.7ms\n",
      "Speed: 0.7ms pre-process, 307.9ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp563\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets208.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets208.png: 416x640 4 persons, 4 bicycles, 416x640 5 persons, 4 bicycles, 1 stop sign, 551.0ms\n",
      "Speed: 0.3ms pre-process, 275.5ms inference, 0.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp564\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets546.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets546.png: 448x640 2 persons, 1 bicycle, 448x640 2 persons, 1 bicycle, 628.3ms\n",
      "Speed: 0.3ms pre-process, 314.2ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp565\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets220.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets220.png: 480x640 15 persons, 6 bicycles, 2 cars, 6 motorcycles, 480x640 14 persons, 6 bicycles, 2 cars, 6 motorcycles, 604.4ms\n",
      "Speed: 0.8ms pre-process, 302.2ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp566\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets234.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets234.png: 448x640 1 person, 1 bicycle, 448x640 1 person, 1 bicycle, 582.2ms\n",
      "Speed: 0.4ms pre-process, 291.1ms inference, 0.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp567\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets552.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets552.png: 448x640 5 persons, 5 cars, 1 motorcycle, 1 dog, 448x640 5 persons, 5 cars, 3 motorcycles, 1 dog, 1 frisbee, 700.1ms\n",
      "Speed: 0.3ms pre-process, 350.1ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp568\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets22.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets22.png: 480x640 2 persons, 5 cars, 1 motorcycle, 480x640 2 persons, 4 cars, 1 motorcycle, 888.7ms\n",
      "Speed: 0.4ms pre-process, 444.4ms inference, 0.9ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp569\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets585.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets585.png: 640x640 1 person, 1 motorcycle, 640x640 1 person, 1 motorcycle, 1021.4ms\n",
      "Speed: 0.6ms pre-process, 510.7ms inference, 1.3ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp570\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets36.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets36.png: 480x640 2 persons, 1 bicycle, 480x640 2 persons, 1 bicycle, 701.0ms\n",
      "Speed: 0.3ms pre-process, 350.5ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp571\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets591.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets591.png: 640x480 1 person, 1 bicycle, 1 book, 640x480 1 person, 1 bicycle, 1 book, 655.5ms\n",
      "Speed: 0.4ms pre-process, 327.7ms inference, 0.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp572\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets744.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets744.png: 480x640 11 persons, 4 motorcycles, 480x640 12 persons, 4 motorcycles, 655.3ms\n",
      "Speed: 0.5ms pre-process, 327.6ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp573\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets750.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets750.png: 640x640 6 persons, 5 cars, 6 motorcycles, 2 trucks, 2 traffic lights, 640x640 5 persons, 5 cars, 6 motorcycles, 2 trucks, 1 traffic light, 845.5ms\n",
      "Speed: 0.5ms pre-process, 422.7ms inference, 1.1ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp574\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets6.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets6.png: 384x640 9 persons, 5 motorcycles, 384x640 10 persons, 5 motorcycles, 549.4ms\n",
      "Speed: 0.3ms pre-process, 274.7ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp575\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets618.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets618.png: 416x640 9 persons, 6 motorcycles, 416x640 9 persons, 6 motorcycles, 597.6ms\n",
      "Speed: 0.3ms pre-process, 298.8ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp576\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets156.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets156.png: 384x640 1 person, 1 motorcycle, 2 cows, 384x640 2 persons, 1 motorcycle, 1 cow, 492.9ms\n",
      "Speed: 0.5ms pre-process, 246.5ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp577\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets630.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets630.png: 480x640 1 person, 1 motorcycle, 480x640 1 person, 1 motorcycle, 606.7ms\n",
      "Speed: 0.3ms pre-process, 303.4ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp578\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets624.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets624.png: 640x448 2 persons, 2 bicycles, 640x448 2 persons, 2 bicycles, 605.6ms\n",
      "Speed: 0.4ms pre-process, 302.8ms inference, 0.5ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp579\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets142.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets142.png: 448x640 3 persons, 2 bicycles, 1 stop sign, 448x640 2 persons, 2 bicycles, 1 stop sign, 1 backpack, 830.7ms\n",
      "Speed: 0.4ms pre-process, 415.4ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp580\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets195.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets195.png: 448x640 6 persons, 7 bicycles, 448x640 7 persons, 7 bicycles, 1 bottle, 546.9ms\n",
      "Speed: 0.3ms pre-process, 273.4ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp581\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets181.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets181.png: 416x640 2 persons, 1 motorcycle, 416x640 3 persons, 1 motorcycle, 581.4ms\n",
      "Speed: 0.4ms pre-process, 290.7ms inference, 0.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp582\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets368.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets368.png: 384x640 1 person, 1 motorcycle, 384x640 1 person, 1 motorcycle, 594.2ms\n",
      "Speed: 0.1ms pre-process, 297.1ms inference, 0.5ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp583\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets432.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets432.png: 416x640 4 persons, 1 motorcycle, 1 backpack, 416x640 5 persons, 1 motorcycle, 2 backpacks, 539.5ms\n",
      "Speed: 0.4ms pre-process, 269.7ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp584\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets354.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets354.png: 352x640 7 persons, 1 car, 8 motorcycles, 352x640 9 persons, 1 car, 8 motorcycles, 493.2ms\n",
      "Speed: 0.4ms pre-process, 246.6ms inference, 1.2ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp585\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets340.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets340.png: 608x640 3 persons, 1 motorcycle, 1 dog, 608x640 2 persons, 1 motorcycle, 1 dog, 781.8ms\n",
      "Speed: 0.5ms pre-process, 390.9ms inference, 1.0ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp586\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets426.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets426.png: 384x640 1 person, 1 motorcycle, 384x640 1 person, 1 motorcycle, 491.2ms\n",
      "Speed: 0.3ms pre-process, 245.6ms inference, 0.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp587\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets397.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets397.png: 416x640 2 persons, 1 motorcycle, 416x640 3 persons, 1 motorcycle, 565.0ms\n",
      "Speed: 0.3ms pre-process, 282.5ms inference, 0.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp588\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets383.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets383.png: 640x640 6 persons, 1 car, 1 motorcycle, 1 truck, 1 baseball bat, 640x640 8 persons, 2 cars, 1 motorcycle, 1 truck, 1 baseball bat, 770.2ms\n",
      "Speed: 0.5ms pre-process, 385.1ms inference, 0.9ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp589\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets382.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets382.png: 448x640 5 persons, 3 cars, 1 motorcycle, 448x640 5 persons, 2 cars, 1 motorcycle, 557.5ms\n",
      "Speed: 0.4ms pre-process, 278.7ms inference, 1.0ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp590\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets396.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets396.png: 448x640 1 person, 1 motorcycle, 448x640 1 person, 1 motorcycle, 632.5ms\n",
      "Speed: 0.3ms pre-process, 316.3ms inference, 0.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp591\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets341.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets341.png: 640x384 1 person, 1 bicycle, 640x384 1 person, 1 bicycle, 544.7ms\n",
      "Speed: 0.3ms pre-process, 272.3ms inference, 0.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp592\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets427.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets427.png: 384x640 1 person, 2 cars, 1 motorcycle, 384x640 1 person, 2 cars, 1 motorcycle, 550.4ms\n",
      "Speed: 0.4ms pre-process, 275.2ms inference, 0.9ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp593\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets433.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets433.png: 384x640 3 persons, 3 bicycles, 1 stop sign, 384x640 3 persons, 3 bicycles, 1 stop sign, 523.8ms\n",
      "Speed: 0.3ms pre-process, 261.9ms inference, 0.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp594\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets355.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets355.png: 480x640 1 person, 2 cars, 1 handbag, 480x640 1 person, 3 cars, 1 chair, 609.2ms\n",
      "Speed: 0.4ms pre-process, 304.6ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp595\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets369.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets369.png: 448x640 4 persons, 2 motorcycles, 2 buss, 1 truck, 448x640 4 persons, 2 motorcycles, 1 bus, 2 trucks, 1 cell phone, 565.4ms\n",
      "Speed: 0.5ms pre-process, 282.7ms inference, 0.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp596\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets180.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets180.png: 384x640 5 persons, 1 car, 3 motorcycles, 384x640 6 persons, 1 car, 3 motorcycles, 469.5ms\n",
      "Speed: 0.3ms pre-process, 234.7ms inference, 0.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp597\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets194.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets194.png: 384x640 6 persons, 1 bicycle, 3 cars, 2 motorcycles, 384x640 6 persons, 2 bicycles, 3 cars, 2 motorcycles, 484.8ms\n",
      "Speed: 0.3ms pre-process, 242.4ms inference, 0.9ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp598\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets625.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets625.png: 448x640 1 person, 1 bicycle, 1 car, 448x640 1 person, 1 bicycle, 1 car, 549.9ms\n",
      "Speed: 0.4ms pre-process, 274.9ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp599\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets143.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets143.png: 384x640 8 persons, 2 cars, 4 motorcycles, 1 bus, 1 truck, 384x640 9 persons, 2 cars, 5 motorcycles, 1 truck, 568.6ms\n",
      "Speed: 0.3ms pre-process, 284.3ms inference, 0.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp600\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets157.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets157.png: 384x640 2 persons, 1 motorcycle, 1 kite, 384x640 2 persons, 1 motorcycle, 1 kite, 520.1ms\n",
      "Speed: 0.6ms pre-process, 260.0ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp601\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets631.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets631.png: 480x640 10 persons, 2 bicycles, 1 motorcycle, 1 backpack, 480x640 14 persons, 4 bicycles, 2 backpacks, 697.2ms\n",
      "Speed: 0.4ms pre-process, 348.6ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp602\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets619.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets619.png: 480x640 9 persons, 5 motorcycles, 1 truck, 480x640 9 persons, 4 motorcycles, 653.9ms\n",
      "Speed: 0.4ms pre-process, 327.0ms inference, 1.1ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp603\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets751.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets751.png: 448x640 7 persons, 5 bicycles, 448x640 7 persons, 5 bicycles, 562.3ms\n",
      "Speed: 0.4ms pre-process, 281.2ms inference, 0.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp604\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets7.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets7.png: 448x640 7 persons, 5 motorcycles, 448x640 8 persons, 5 motorcycles, 652.8ms\n",
      "Speed: 0.5ms pre-process, 326.4ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp605\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets745.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets745.png: 320x640 1 person, 1 motorcycle, 320x640 1 person, 1 motorcycle, 461.2ms\n",
      "Speed: 0.3ms pre-process, 230.6ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp606\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets590.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets590.png: 416x640 5 persons, 1 car, 3 motorcycles, 416x640 4 persons, 1 car, 3 motorcycles, 589.1ms\n",
      "Speed: 0.3ms pre-process, 294.6ms inference, 1.5ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp607\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets37.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets37.png: 480x640 6 persons, 7 cars, 4 motorcycles, 2 buss, 480x640 6 persons, 1 bicycle, 10 cars, 3 motorcycles, 1 bus, 1 backpack, 766.3ms\n",
      "Speed: 0.3ms pre-process, 383.2ms inference, 2.1ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp608\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets584.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets584.png: 640x448 2 persons, 1 bicycle, 640x448 2 persons, 1 bicycle, 744.9ms\n",
      "Speed: 0.3ms pre-process, 372.5ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp609\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets23.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets23.png: 512x640 4 persons, 3 motorcycles, 1 backpack, 512x640 4 persons, 3 motorcycles, 1 backpack, 699.6ms\n",
      "Speed: 0.4ms pre-process, 349.8ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp610\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets235.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets235.png: 448x640 2 persons, 2 bicycles, 10 cars, 1 backpack, 448x640 2 persons, 2 bicycles, 12 cars, 1 backpack, 617.9ms\n",
      "Speed: 0.4ms pre-process, 308.9ms inference, 0.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp611\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets553.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets553.png: 448x640 5 persons, 2 bicycles, 4 cars, 1 motorcycle, 448x640 7 persons, 3 bicycles, 4 cars, 3 motorcycles, 1 truck, 803.1ms\n",
      "Speed: 0.5ms pre-process, 401.6ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp612\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets547.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets547.png: 480x640 12 persons, 2 bicycles, 6 cars, 1 truck, 480x640 13 persons, 2 bicycles, 6 cars, 1 truck, 794.8ms\n",
      "Speed: 0.4ms pre-process, 397.4ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp613\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets221.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets221.png: 288x640 11 persons, 3 bicycles, 4 cars, 1 motorcycle, 1 backpack, 288x640 11 persons, 4 bicycles, 4 cars, 1 motorcycle, 3 backpacks, 517.4ms\n",
      "Speed: 0.2ms pre-process, 258.7ms inference, 0.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp614\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets209.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets209.png: 512x640 2 persons, 1 car, 1 motorcycle, 512x640 2 persons, 1 car, 1 motorcycle, 783.6ms\n",
      "Speed: 0.4ms pre-process, 391.8ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp615\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets579.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets579.png: 384x640 1 person, 1 motorcycle, 384x640 1 person, 1 motorcycle, 534.6ms\n",
      "Speed: 0.4ms pre-process, 267.3ms inference, 0.5ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp616\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets551.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets551.png: 448x640 1 person, 1 bicycle, 448x640 1 person, 2 bicycles, 746.4ms\n",
      "Speed: 0.3ms pre-process, 373.2ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp617\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets237.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets237.png: 448x640 2 persons, 1 motorcycle, 448x640 2 persons, 1 motorcycle, 603.9ms\n",
      "Speed: 0.4ms pre-process, 301.9ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp618\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets223.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets223.png: 480x640 5 persons, 2 bicycles, 1 car, 4 motorcycles, 1 chair, 480x640 5 persons, 1 bicycle, 1 car, 4 motorcycles, 1 chair, 719.0ms\n",
      "Speed: 0.4ms pre-process, 359.5ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp619\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets545.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets545.png: 640x416 1 person, 640x416 1 person, 549.2ms\n",
      "Speed: 0.3ms pre-process, 274.6ms inference, 0.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp620\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets592.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets592.png: 512x640 14 persons, 4 bicycles, 1 traffic light, 1 dog, 512x640 14 persons, 3 bicycles, 1 dog, 772.2ms\n",
      "Speed: 0.4ms pre-process, 386.1ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp621\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets35.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets35.png: 480x640 1 person, 1 bicycle, 1 backpack, 480x640 1 person, 1 bicycle, 1 backpack, 619.4ms\n",
      "Speed: 0.2ms pre-process, 309.7ms inference, 0.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp622\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets586.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets586.png: 448x640 10 persons, 5 motorcycles, 1 backpack, 448x640 11 persons, 6 motorcycles, 1 backpack, 683.4ms\n",
      "Speed: 0.4ms pre-process, 341.7ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp623\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets21.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets21.png: 448x640 1 person, 448x640 1 person, 780.6ms\n",
      "Speed: 0.3ms pre-process, 390.3ms inference, 1.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp624\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets5.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets5.png: 416x640 4 persons, 1 car, 2 motorcycles, 1 bus, 2 backpacks, 416x640 4 persons, 1 car, 1 motorcycle, 2 buss, 1 backpack, 676.2ms\n",
      "Speed: 0.3ms pre-process, 338.1ms inference, 1.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp625\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets753.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets753.png: 448x640 2 persons, 1 motorcycle, 2 parking meters, 448x640 2 persons, 2 motorcycles, 2 parking meters, 626.9ms\n",
      "Speed: 0.3ms pre-process, 313.5ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp626\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets747.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets747.png: 480x640 8 persons, 1 bicycle, 2 cars, 2 motorcycles, 1 truck, 1 handbag, 480x640 8 persons, 2 bicycles, 1 car, 2 motorcycles, 1 truck, 2 handbags, 625.8ms\n",
      "Speed: 0.4ms pre-process, 312.9ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp627\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets169.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets169.png: 448x640 3 persons, 1 car, 1 motorcycle, 1 traffic light, 448x640 3 persons, 1 car, 1 motorcycle, 1 traffic light, 613.6ms\n",
      "Speed: 0.4ms pre-process, 306.8ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp628\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets141.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets141.png: 320x640 2 persons, 1 bicycle, 320x640 2 persons, 1 bicycle, 438.9ms\n",
      "Speed: 0.3ms pre-process, 219.5ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp629\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets627.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets627.png: 384x640 2 persons, 1 motorcycle, 1 backpack, 384x640 2 persons, 1 motorcycle, 1 backpack, 560.8ms\n",
      "Speed: 0.5ms pre-process, 280.4ms inference, 2.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp630\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets633.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets633.png: 480x640 10 persons, 2 bicycles, 1 motorcycle, 2 umbrellas, 1 tie, 3 chairs, 480x640 11 persons, 2 bicycles, 1 motorcycle, 3 umbrellas, 1 tie, 2 chairs, 686.6ms\n",
      "Speed: 1.5ms pre-process, 343.3ms inference, 1.2ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp631\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets155.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets155.png: 640x480 2 persons, 1 bicycle, 640x480 2 persons, 1 bicycle, 674.8ms\n",
      "Speed: 0.4ms pre-process, 337.4ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp632\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets182.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets182.png: 384x640 1 person, 2 cars, 1 motorcycle, 1 backpack, 384x640 1 person, 1 bicycle, 2 cars, 1 motorcycle, 1 backpack, 533.7ms\n",
      "Speed: 0.3ms pre-process, 266.9ms inference, 0.5ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp633\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets196.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets196.png: 448x640 7 persons, 5 motorcycles, 1 handbag, 448x640 7 persons, 6 motorcycles, 1 backpack, 1 handbag, 586.0ms\n",
      "Speed: 0.7ms pre-process, 293.0ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp634\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets419.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets419.png: 448x640 2 persons, 2 bicycles, 448x640 2 persons, 2 bicycles, 584.5ms\n",
      "Speed: 0.4ms pre-process, 292.2ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp635\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets425.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets425.png: 448x640 5 persons, 5 cars, 1 motorcycle, 1 dog, 448x640 5 persons, 5 cars, 3 motorcycles, 1 dog, 1 frisbee, 634.5ms\n",
      "Speed: 0.3ms pre-process, 317.2ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp636\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets343.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets343.png: 448x640 1 person, 1 motorcycle, 1 backpack, 1 handbag, 448x640 1 person, 1 motorcycle, 1 handbag, 682.9ms\n",
      "Speed: 0.4ms pre-process, 341.5ms inference, 0.9ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp637\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets357.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets357.png: 384x640 2 persons, 1 motorcycle, 384x640 2 persons, 1 motorcycle, 523.1ms\n",
      "Speed: 0.4ms pre-process, 261.5ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp638\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets431.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets431.png: 448x640 4 persons, 1 motorcycle, 448x640 4 persons, 2 motorcycles, 549.4ms\n",
      "Speed: 0.4ms pre-process, 274.7ms inference, 0.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp639\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets380.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets380.png: 576x640 3 persons, 2 cars, 3 motorcycles, 576x640 3 persons, 4 cars, 3 motorcycles, 1 backpack, 759.3ms\n",
      "Speed: 0.4ms pre-process, 379.7ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp640\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets394.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets394.png: 448x640 6 persons, 3 motorcycles, 448x640 6 persons, 3 motorcycles, 644.4ms\n",
      "Speed: 0.2ms pre-process, 322.2ms inference, 0.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp641\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets395.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets395.png: 384x640 4 persons, 4 cars, 4 motorcycles, 1 dog, 384x640 3 persons, 4 cars, 3 motorcycles, 1 dog, 573.8ms\n",
      "Speed: 0.3ms pre-process, 286.9ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp642\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets381.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets381.png: 448x640 5 persons, 5 bicycles, 3 cars, 2 buss, 1 truck, 448x640 6 persons, 5 bicycles, 6 cars, 2 buss, 1 backpack, 598.5ms\n",
      "Speed: 0.3ms pre-process, 299.2ms inference, 0.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp643\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets356.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets356.png: 448x640 3 persons, 3 bicycles, 448x640 3 persons, 3 bicycles, 601.6ms\n",
      "Speed: 0.3ms pre-process, 300.8ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp644\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets430.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets430.png: 512x640 4 persons, 2 bicycles, 4 cars, 1 bus, 2 traffic lights, 512x640 4 persons, 2 bicycles, 4 cars, 1 bus, 2 traffic lights, 743.8ms\n",
      "Speed: 0.6ms pre-process, 371.9ms inference, 0.9ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp645\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets424.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets424.png: 448x640 5 persons, 1 bicycle, 1 car, 2 motorcycles, 448x640 6 persons, 1 bicycle, 1 car, 2 motorcycles, 601.7ms\n",
      "Speed: 0.4ms pre-process, 300.8ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp646\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets342.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets342.png: 512x640 2 persons, 1 car, 1 motorcycle, 1 potted plant, 512x640 2 persons, 1 car, 1 motorcycle, 1 potted plant, 819.5ms\n",
      "Speed: 0.4ms pre-process, 409.8ms inference, 0.9ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp647\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets418.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets418.png: 448x640 1 person, 1 motorcycle, 448x640 1 person, 1 motorcycle, 556.6ms\n",
      "Speed: 0.4ms pre-process, 278.3ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp648\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets197.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets197.png: 512x640 2 persons, 1 motorcycle, 1 backpack, 1 umbrella, 1 handbag, 1 potted plant, 512x640 3 persons, 1 motorcycle, 1 backpack, 1 umbrella, 1 handbag, 1 potted plant, 749.4ms\n",
      "Speed: 0.4ms pre-process, 374.7ms inference, 0.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp649\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets183.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets183.png: 448x640 1 person, 1 motorcycle, 448x640 1 person, 1 motorcycle, 645.5ms\n",
      "Speed: 0.3ms pre-process, 322.8ms inference, 0.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp650\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets632.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets632.png: 480x640 13 persons, 2 motorcycles, 480x640 12 persons, 3 motorcycles, 927.5ms\n",
      "Speed: 0.9ms pre-process, 463.8ms inference, 1.2ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp651\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets154.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets154.png: 640x512 8 persons, 2 cars, 4 motorcycles, 1 bus, 640x512 12 persons, 4 cars, 4 motorcycles, 1 bus, 1 backpack, 783.6ms\n",
      "Speed: 0.2ms pre-process, 391.8ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp652\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets140.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets140.png: 448x640 3 persons, 1 car, 2 motorcycles, 1 truck, 448x640 3 persons, 1 car, 1 motorcycle, 700.1ms\n",
      "Speed: 0.4ms pre-process, 350.0ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp653\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets626.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets626.png: 384x640 1 person, 1 bicycle, 384x640 1 person, 1 bicycle, 536.4ms\n",
      "Speed: 0.4ms pre-process, 268.2ms inference, 0.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp654\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets168.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets168.png: 640x640 1 person, 1 motorcycle, 1 cell phone, 640x640 1 person, 1 motorcycle, 791.2ms\n",
      "Speed: 0.5ms pre-process, 395.6ms inference, 1.2ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp655\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets746.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets746.png: 640x448 9 persons, 1 bicycle, 640x448 8 persons, 3 bicycles, 1 motorcycle, 1 backpack, 1 suitcase, 579.6ms\n",
      "Speed: 0.4ms pre-process, 289.8ms inference, 1.2ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp656\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets4.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets4.png: 416x640 1 person, 1 motorcycle, 416x640 1 person, 1 motorcycle, 549.9ms\n",
      "Speed: 0.3ms pre-process, 275.0ms inference, 0.5ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp657\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets752.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets752.png: 384x640 5 persons, 5 bicycles, 2 handbags, 384x640 5 persons, 5 bicycles, 1 handbag, 500.0ms\n",
      "Speed: 0.3ms pre-process, 250.0ms inference, 0.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp658\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets20.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets20.png: 640x480 2 persons, 2 cars, 2 motorcycles, 640x480 2 persons, 3 cars, 2 motorcycles, 1 backpack, 613.0ms\n",
      "Speed: 0.4ms pre-process, 306.5ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp659\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets587.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets587.png: 448x640 1 person, 1 motorcycle, 448x640 1 person, 1 motorcycle, 547.7ms\n",
      "Speed: 0.3ms pre-process, 273.8ms inference, 0.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp660\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets34.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets34.png: 448x640 1 person, 1 motorcycle, 448x640 1 person, 1 motorcycle, 560.4ms\n",
      "Speed: 0.3ms pre-process, 280.2ms inference, 1.3ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp661\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets593.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets593.png: 384x640 9 persons, 4 motorcycles, 384x640 12 persons, 1 car, 4 motorcycles, 496.2ms\n",
      "Speed: 0.4ms pre-process, 248.1ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp662\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets222.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets222.png: 480x640 8 persons, 3 bicycles, 1 car, 1 motorcycle, 1 traffic light, 1 backpack, 3 umbrellas, 1 handbag, 480x640 9 persons, 3 bicycles, 1 car, 1 motorcycle, 1 backpack, 7 umbrellas, 1 handbag, 621.5ms\n",
      "Speed: 0.4ms pre-process, 310.7ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp663\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets544.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets544.png: 544x640 1 person, 1 bicycle, 2 cars, 544x640 1 person, 1 bicycle, 1 car, 675.8ms\n",
      "Speed: 0.4ms pre-process, 337.9ms inference, 0.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp664\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets550.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets550.png: 416x640 3 persons, 2 cars, 2 motorcycles, 1 truck, 416x640 3 persons, 2 cars, 2 motorcycles, 1 truck, 530.8ms\n",
      "Speed: 0.4ms pre-process, 265.4ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp665\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets236.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets236.png: 416x640 6 persons, 3 bicycles, 416x640 6 persons, 3 bicycles, 559.3ms\n",
      "Speed: 0.4ms pre-process, 279.7ms inference, 2.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp666\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets578.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets578.png: 384x640 3 persons, 1 bicycle, 2 cars, 384x640 3 persons, 1 bicycle, 2 cars, 1 handbag, 483.2ms\n",
      "Speed: 0.3ms pre-process, 241.6ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp667\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets232.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets232.png: 640x640 2 persons, 1 motorcycle, 640x640 2 persons, 1 motorcycle, 874.2ms\n",
      "Speed: 0.4ms pre-process, 437.1ms inference, 0.9ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp668\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets554.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets554.png: 384x640 9 persons, 4 motorcycles, 384x640 9 persons, 5 motorcycles, 537.2ms\n",
      "Speed: 0.4ms pre-process, 268.6ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp669\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets540.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets540.png: 640x448 1 person, 1 motorcycle, 640x448 2 persons, 1 motorcycle, 583.1ms\n",
      "Speed: 0.3ms pre-process, 291.6ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp670\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets226.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets226.png: 640x640 1 person, 1 bicycle, 640x640 1 person, 1 bicycle, 926.7ms\n",
      "Speed: 0.5ms pre-process, 463.3ms inference, 1.2ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp671\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets568.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets568.png: 448x640 2 persons, 1 car, 1 motorcycle, 448x640 2 persons, 1 car, 1 motorcycle, 565.7ms\n",
      "Speed: 0.4ms pre-process, 282.8ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp672\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets597.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets597.png: 480x640 7 persons, 4 motorcycles, 1 truck, 1 backpack, 480x640 7 persons, 1 car, 3 motorcycles, 1 handbag, 644.4ms\n",
      "Speed: 0.6ms pre-process, 322.2ms inference, 1.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp673\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets30.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets30.png: 640x448 2 persons, 2 bicycles, 2 cars, 640x448 3 persons, 2 bicycles, 2 cars, 592.9ms\n",
      "Speed: 0.5ms pre-process, 296.5ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp674\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets583.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets583.png: 576x640 1 person, 1 bicycle, 1 suitcase, 576x640 1 person, 1 bicycle, 687.2ms\n",
      "Speed: 0.5ms pre-process, 343.6ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp675\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets24.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets24.png: 544x640 1 person, 1 bicycle, 544x640 1 person, 1 bicycle, 675.0ms\n",
      "Speed: 0.5ms pre-process, 337.5ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp676\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets18.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets18.png: 384x640 8 persons, 1 motorcycle, 1 handbag, 384x640 10 persons, 1 motorcycle, 2 handbags, 508.4ms\n",
      "Speed: 0.4ms pre-process, 254.2ms inference, 0.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp677\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets756.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets756.png: 448x640 1 person, 1 bicycle, 448x640 1 person, 1 bicycle, 591.5ms\n",
      "Speed: 0.3ms pre-process, 295.7ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp678\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets0.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets0.png: 448x640 4 persons, 4 bicycles, 448x640 4 persons, 2 bicycles, 581.3ms\n",
      "Speed: 0.6ms pre-process, 290.6ms inference, 0.9ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp679\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets742.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets742.png: 384x640 1 person, 2 cars, 1 motorcycle, 1 backpack, 384x640 1 person, 1 bicycle, 2 cars, 1 motorcycle, 1 backpack, 476.1ms\n",
      "Speed: 0.3ms pre-process, 238.0ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp680\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets622.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets622.png: 544x640 8 persons, 2 bicycles, 2 handbags, 544x640 9 persons, 2 bicycles, 1 backpack, 2 handbags, 1 cell phone, 701.8ms\n",
      "Speed: 0.4ms pre-process, 350.9ms inference, 0.9ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp681\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets144.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets144.png: 480x640 8 persons, 2 motorcycles, 3 backpacks, 480x640 9 persons, 2 motorcycles, 6 backpacks, 595.0ms\n",
      "Speed: 0.4ms pre-process, 297.5ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp682\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets150.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets150.png: 480x640 8 persons, 2 cars, 3 motorcycles, 480x640 12 persons, 3 cars, 4 motorcycles, 693.8ms\n",
      "Speed: 0.5ms pre-process, 346.9ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp683\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets636.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets636.png: 384x640 3 persons, 2 bicycles, 384x640 3 persons, 2 bicycles, 534.5ms\n",
      "Speed: 0.3ms pre-process, 267.2ms inference, 0.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp684\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets178.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets178.png: 416x640 2 persons, 1 bicycle, 1 cell phone, 416x640 2 persons, 1 bicycle, 507.6ms\n",
      "Speed: 0.4ms pre-process, 253.8ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp685\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets187.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets187.png: 384x640 1 person, 2 cars, 1 motorcycle, 384x640 1 person, 2 cars, 1 motorcycle, 521.3ms\n",
      "Speed: 0.4ms pre-process, 260.7ms inference, 0.5ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp686\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets193.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets193.png: 480x640 1 person, 1 motorcycle, 1 backpack, 480x640 1 person, 1 motorcycle, 628.0ms\n",
      "Speed: 0.4ms pre-process, 314.0ms inference, 0.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp687\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets346.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets346.png: 640x640 1 person, 1 bicycle, 640x640 1 person, 1 bicycle, 881.8ms\n",
      "Speed: 0.5ms pre-process, 440.9ms inference, 1.1ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp688\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets420.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets420.png: 640x480 1 person, 1 motorcycle, 640x480 1 person, 1 motorcycle, 947.7ms\n",
      "Speed: 0.1ms pre-process, 473.9ms inference, 0.9ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp689\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets434.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets434.png: 480x640 1 person, 2 cars, 1 motorcycle, 480x640 1 person, 2 cars, 1 motorcycle, 712.3ms\n",
      "Speed: 0.3ms pre-process, 356.2ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp690\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets352.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets352.png: 384x640 1 person, 1 motorcycle, 384x640 1 person, 1 motorcycle, 522.4ms\n",
      "Speed: 0.3ms pre-process, 261.2ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp691\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets408.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets408.png: 352x640 2 persons, 2 motorcycles, 352x640 2 persons, 2 motorcycles, 528.9ms\n",
      "Speed: 0.2ms pre-process, 264.4ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp692\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets385.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets385.png: 448x640 10 persons, 5 motorcycles, 448x640 11 persons, 6 motorcycles, 561.0ms\n",
      "Speed: 0.4ms pre-process, 280.5ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp693\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets391.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets391.png: 512x640 1 person, 1 motorcycle, 512x640 1 person, 1 motorcycle, 752.7ms\n",
      "Speed: 0.5ms pre-process, 376.4ms inference, 0.9ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp694\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets390.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets390.png: 640x640 1 person, 1 motorcycle, 640x640 1 person, 1 motorcycle, 809.2ms\n",
      "Speed: 0.5ms pre-process, 404.6ms inference, 0.9ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp695\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets384.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets384.png: 640x512 1 person, 1 bicycle, 1 cell phone, 640x512 1 person, 1 bicycle, 811.2ms\n",
      "Speed: 0.4ms pre-process, 405.6ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp696\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets409.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets409.png: 448x640 7 persons, 1 bicycle, 1 car, 3 umbrellas, 448x640 7 persons, 1 bicycle, 1 car, 3 umbrellas, 648.9ms\n",
      "Speed: 0.3ms pre-process, 324.4ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp697\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets435.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets435.png: 384x640 1 person, 1 motorcycle, 384x640 1 person, 1 motorcycle, 537.5ms\n",
      "Speed: 0.5ms pre-process, 268.7ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp698\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets353.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets353.png: 416x640 10 persons, 7 motorcycles, 416x640 11 persons, 8 motorcycles, 568.0ms\n",
      "Speed: 0.5ms pre-process, 284.0ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp699\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets347.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets347.png: 448x640 2 persons, 1 bicycle, 1 motorcycle, 448x640 2 persons, 2 motorcycles, 641.1ms\n",
      "Speed: 0.4ms pre-process, 320.6ms inference, 0.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp700\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets421.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets421.png: 640x480 3 persons, 640x480 3 persons, 660.5ms\n",
      "Speed: 0.4ms pre-process, 330.2ms inference, 0.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp701\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets192.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets192.png: 352x640 1 person, 2 cars, 1 motorcycle, 352x640 1 person, 2 cars, 1 motorcycle, 1 truck, 620.9ms\n",
      "Speed: 0.7ms pre-process, 310.4ms inference, 1.0ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp702\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets186.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets186.png: 640x480 1 person, 1 bicycle, 640x480 1 person, 1 bicycle, 711.7ms\n",
      "Speed: 0.3ms pre-process, 355.9ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp703\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets179.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets179.png: 480x640 6 persons, 1 bicycle, 1 backpack, 1 skateboard, 480x640 6 persons, 1 bicycle, 1 backpack, 889.8ms\n",
      "Speed: 0.5ms pre-process, 444.9ms inference, 1.0ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp704\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets151.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets151.png: 384x640 2 persons, 4 cars, 1 motorcycle, 1 bench, 384x640 2 persons, 4 cars, 1 motorcycle, 1 bench, 910.2ms\n",
      "Speed: 0.4ms pre-process, 455.1ms inference, 1.4ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp705\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets637.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets637.png: 448x640 3 persons, 1 car, 3 motorcycles, 1 backpack, 448x640 3 persons, 1 car, 3 motorcycles, 1 backpack, 1 sports ball, 601.5ms\n",
      "Speed: 0.4ms pre-process, 300.8ms inference, 0.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp706\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets623.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets623.png: 448x640 1 person, 448x640 1 person, 609.5ms\n",
      "Speed: 0.4ms pre-process, 304.8ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp707\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets145.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets145.png: 320x640 4 persons, 3 bicycles, 1 boat, 320x640 4 persons, 3 bicycles, 1 boat, 444.6ms\n",
      "Speed: 1.0ms pre-process, 222.3ms inference, 0.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp708\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets743.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets743.png: 480x640 2 persons, 1 car, 1 motorcycle, 1 potted plant, 480x640 3 persons, 1 car, 1 motorcycle, 1 cup, 2 potted plants, 639.9ms\n",
      "Speed: 0.4ms pre-process, 320.0ms inference, 1.2ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp709\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets757.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets757.png: 448x640 10 persons, 1 car, 3 motorcycles, 448x640 14 persons, 1 car, 3 motorcycles, 584.9ms\n",
      "Speed: 0.4ms pre-process, 292.4ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp710\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets1.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets1.png: 480x640 1 person, 1 motorcycle, 480x640 1 person, 1 motorcycle, 635.1ms\n",
      "Speed: 0.4ms pre-process, 317.6ms inference, 1.2ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp711\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets19.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets19.png: 480x640 2 persons, 2 bicycles, 2 bottles, 480x640 2 persons, 2 bicycles, 2 bottles, 616.4ms\n",
      "Speed: 0.5ms pre-process, 308.2ms inference, 0.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp712\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets25.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets25.png: 384x640 2 persons, 2 bicycles, 1 backpack, 384x640 2 persons, 2 bicycles, 2 backpacks, 573.4ms\n",
      "Speed: 0.3ms pre-process, 286.7ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp713\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets582.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets582.png: 448x640 3 persons, 3 bicycles, 2 backpacks, 448x640 3 persons, 3 bicycles, 3 backpacks, 615.4ms\n",
      "Speed: 0.3ms pre-process, 307.7ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp714\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets31.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets31.png: 512x640 15 persons, 4 bicycles, 1 stop sign, 2 backpacks, 512x640 15 persons, 3 bicycles, 1 stop sign, 2 backpacks, 705.4ms\n",
      "Speed: 0.4ms pre-process, 352.7ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp715\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets596.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets596.png: 384x640 9 persons, 4 bicycles, 384x640 8 persons, 4 bicycles, 491.6ms\n",
      "Speed: 0.8ms pre-process, 245.8ms inference, 0.9ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp716\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets569.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets569.png: 448x640 5 persons, 1 bicycle, 1 car, 2 motorcycles, 448x640 6 persons, 1 bicycle, 1 car, 2 motorcycles, 578.6ms\n",
      "Speed: 0.4ms pre-process, 289.3ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp717\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets541.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets541.png: 384x640 4 persons, 2 motorcycles, 384x640 4 persons, 2 motorcycles, 482.4ms\n",
      "Speed: 0.3ms pre-process, 241.2ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp718\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets227.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets227.png: 640x448 3 persons, 1 bicycle, 640x448 3 persons, 1 bicycle, 608.3ms\n",
      "Speed: 0.4ms pre-process, 304.1ms inference, 0.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp719\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets233.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets233.png: 448x640 4 persons, 1 motorcycle, 1 handbag, 448x640 3 persons, 1 motorcycle, 1 handbag, 733.0ms\n",
      "Speed: 0.4ms pre-process, 366.5ms inference, 4.4ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp720\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets555.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets555.png: 448x640 10 persons, 10 bicycles, 2 cars, 1 handbag, 448x640 11 persons, 10 bicycles, 3 cars, 1 handbag, 829.3ms\n",
      "Speed: 0.6ms pre-process, 414.7ms inference, 1.2ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp721\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets225.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets225.png: 448x640 1 person, 1 motorcycle, 448x640 1 person, 1 motorcycle, 659.6ms\n",
      "Speed: 0.3ms pre-process, 329.8ms inference, 1.1ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp722\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets543.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets543.png: 640x480 1 person, 1 bicycle, 1 car, 640x480 1 person, 1 bicycle, 1 car, 757.9ms\n",
      "Speed: 0.4ms pre-process, 378.9ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp723\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets557.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets557.png: 384x640 13 persons, 7 bicycles, 1 bus, 1 handbag, 384x640 13 persons, 7 bicycles, 1 bus, 1 backpack, 694.5ms\n",
      "Speed: 0.4ms pre-process, 347.3ms inference, 1.0ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp724\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets231.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets231.png: 384x640 8 persons, 5 motorcycles, 2 backpacks, 384x640 7 persons, 6 motorcycles, 2 backpacks, 632.1ms\n",
      "Speed: 0.2ms pre-process, 316.0ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp725\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets219.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets219.png: 448x640 12 persons, 1 car, 4 motorcycles, 448x640 12 persons, 1 car, 4 motorcycles, 1 backpack, 792.6ms\n",
      "Speed: 0.4ms pre-process, 396.3ms inference, 1.0ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp726\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets27.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets27.png: 480x640 1 person, 2 cars, 1 motorcycle, 2 trucks, 480x640 1 person, 2 cars, 1 motorcycle, 1 truck, 687.9ms\n",
      "Speed: 0.4ms pre-process, 343.9ms inference, 0.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp727\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets580.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets580.png: 448x640 5 persons, 11 motorcycles, 1 handbag, 448x640 5 persons, 11 motorcycles, 1 handbag, 699.1ms\n",
      "Speed: 0.4ms pre-process, 349.6ms inference, 0.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp728\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets33.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets33.png: 448x640 4 persons, 1 motorcycle, 448x640 4 persons, 3 motorcycles, 1 backpack, 681.3ms\n",
      "Speed: 0.4ms pre-process, 340.7ms inference, 4.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp729\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets594.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets594.png: 416x640 4 persons, 3 motorcycles, 416x640 5 persons, 3 motorcycles, 1 handbag, 555.8ms\n",
      "Speed: 0.4ms pre-process, 277.9ms inference, 0.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp730\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets741.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets741.png: 480x640 1 person, 1 motorcycle, 480x640 1 person, 1 motorcycle, 694.6ms\n",
      "Speed: 0.4ms pre-process, 347.3ms inference, 2.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp731\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets3.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets3.png: 352x640 4 persons, 3 bicycles, 1 car, 352x640 5 persons, 3 bicycles, 1 car, 480.6ms\n",
      "Speed: 0.3ms pre-process, 240.3ms inference, 0.9ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp732\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets755.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets755.png: 448x640 2 persons, 1 bicycle, 448x640 2 persons, 2 bicycles, 717.6ms\n",
      "Speed: 0.4ms pre-process, 358.8ms inference, 0.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp733\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets635.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets635.png: 384x640 2 persons, 3 cars, 2 motorcycles, 1 truck, 384x640 3 persons, 1 bicycle, 3 cars, 2 motorcycles, 520.9ms\n",
      "Speed: 0.3ms pre-process, 260.4ms inference, 1.4ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp734\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets153.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets153.png: 640x480 1 person, 1 bicycle, 640x480 1 person, 1 bicycle, 1 backpack, 597.3ms\n",
      "Speed: 0.4ms pre-process, 298.6ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp735\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets147.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets147.png: 448x640 2 persons, 2 bicycles, 448x640 2 persons, 2 bicycles, 560.2ms\n",
      "Speed: 0.6ms pre-process, 280.1ms inference, 1.1ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp736\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets621.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets621.png: 608x640 1 person, 1 car, 1 motorcycle, 608x640 2 persons, 1 car, 1 motorcycle, 855.9ms\n",
      "Speed: 0.4ms pre-process, 427.9ms inference, 0.9ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp737\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets609.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets609.png: 448x640 17 persons, 12 bicycles, 2 cars, 1 handbag, 1 tie, 448x640 17 persons, 12 bicycles, 3 cars, 1 backpack, 1 handbag, 571.0ms\n",
      "Speed: 0.4ms pre-process, 285.5ms inference, 2.1ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp738\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets190.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets190.png: 384x640 11 persons, 1 car, 4 motorcycles, 1 truck, 1 traffic light, 1 umbrella, 384x640 13 persons, 1 car, 5 motorcycles, 1 truck, 1 traffic light, 495.5ms\n",
      "Speed: 0.4ms pre-process, 247.7ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp739\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets184.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets184.png: 480x640 1 person, 1 bicycle, 480x640 1 person, 1 bicycle, 671.4ms\n",
      "Speed: 0.3ms pre-process, 335.7ms inference, 0.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp740\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets351.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets351.png: 448x640 14 persons, 10 motorcycles, 448x640 13 persons, 12 motorcycles, 576.8ms\n",
      "Speed: 0.3ms pre-process, 288.4ms inference, 1.4ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp741\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets437.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets437.png: 384x640 4 persons, 2 motorcycles, 384x640 4 persons, 2 motorcycles, 1 backpack, 1 potted plant, 513.5ms\n",
      "Speed: 0.8ms pre-process, 256.8ms inference, 0.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp742\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets423.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets423.png: 640x480 2 persons, 1 motorcycle, 640x480 2 persons, 1 motorcycle, 619.4ms\n",
      "Speed: 0.4ms pre-process, 309.7ms inference, 0.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp743\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets345.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets345.png: 448x640 10 persons, 2 backpacks, 448x640 10 persons, 1 backpack, 1 handbag, 625.5ms\n",
      "Speed: 0.3ms pre-process, 312.7ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp744\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets379.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets379.png: 384x640 1 person, 1 motorcycle, 384x640 1 person, 1 motorcycle, 497.8ms\n",
      "Speed: 0.3ms pre-process, 248.9ms inference, 0.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp745\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets392.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets392.png: 544x640 2 persons, 3 motorcycles, 2 backpacks, 1 handbag, 544x640 4 persons, 3 motorcycles, 2 backpacks, 1 handbag, 705.7ms\n",
      "Speed: 0.9ms pre-process, 352.9ms inference, 1.4ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp746\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets386.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets386.png: 416x640 7 persons, 6 bicycles, 1 backpack, 416x640 8 persons, 6 bicycles, 1 backpack, 570.1ms\n",
      "Speed: 0.3ms pre-process, 285.0ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp747\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets387.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets387.png: 384x640 7 persons, 1 car, 3 motorcycles, 1 backpack, 384x640 9 persons, 1 car, 4 motorcycles, 2 backpacks, 519.1ms\n",
      "Speed: 0.4ms pre-process, 259.6ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp748\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets393.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets393.png: 512x640 4 persons, 2 bicycles, 4 cars, 1 bus, 2 traffic lights, 512x640 4 persons, 2 bicycles, 4 cars, 1 bus, 2 traffic lights, 754.4ms\n",
      "Speed: 0.4ms pre-process, 377.2ms inference, 1.1ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp749\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets378.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets378.png: 640x480 7 persons, 1 bicycle, 2 cars, 1 backpack, 640x480 7 persons, 2 bicycles, 2 cars, 2 backpacks, 2716.4ms\n",
      "Speed: 0.7ms pre-process, 1358.2ms inference, 2.5ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp750\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets422.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets422.png: 352x640 14 persons, 1 car, 7 motorcycles, 2 handbags, 352x640 13 persons, 1 car, 8 motorcycles, 2 handbags, 654.1ms\n",
      "Speed: 0.9ms pre-process, 327.0ms inference, 0.9ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp751\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets344.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets344.png: 384x640 13 persons, 9 bicycles, 1 handbag, 384x640 13 persons, 10 bicycles, 1 traffic light, 561.4ms\n",
      "Speed: 0.9ms pre-process, 280.7ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp752\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets350.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets350.png: 448x640 1 person, 1 bicycle, 448x640 1 person, 1 bicycle, 578.6ms\n",
      "Speed: 0.4ms pre-process, 289.3ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp753\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets436.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets436.png: 640x448 2 persons, 640x448 2 persons, 1 bicycle, 1 tennis racket, 549.2ms\n",
      "Speed: 0.5ms pre-process, 274.6ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp754\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets185.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets185.png: 480x640 2 persons, 1 car, 1 backpack, 480x640 2 persons, 1 car, 1 motorcycle, 1 backpack, 664.7ms\n",
      "Speed: 0.3ms pre-process, 332.4ms inference, 0.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp755\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets191.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets191.png: 384x640 1 person, 1 bicycle, 1 motorcycle, 384x640 1 person, 1 bicycle, 576.7ms\n",
      "Speed: 0.3ms pre-process, 288.3ms inference, 0.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp756\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets608.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets608.png: 384x640 3 persons, 3 cars, 1 motorcycle, 384x640 3 persons, 2 cars, 1 motorcycle, 494.4ms\n",
      "Speed: 0.3ms pre-process, 247.2ms inference, 6.2ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp757\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets146.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets146.png: 480x640 7 persons, 4 motorcycles, 1 truck, 2 backpacks, 480x640 8 persons, 1 car, 5 motorcycles, 1 truck, 2 backpacks, 658.3ms\n",
      "Speed: 0.4ms pre-process, 329.2ms inference, 1.2ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp758\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets620.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets620.png: 416x640 7 persons, 5 bicycles, 4 cars, 1 bus, 3 backpacks, 416x640 7 persons, 6 bicycles, 4 cars, 1 bus, 3 backpacks, 541.1ms\n",
      "Speed: 0.4ms pre-process, 270.5ms inference, 0.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp759\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets634.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets634.png: 448x640 3 persons, 1 motorcycle, 1 stop sign, 448x640 2 persons, 1 car, 1 motorcycle, 1 stop sign, 566.1ms\n",
      "Speed: 0.4ms pre-process, 283.1ms inference, 0.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp760\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets152.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets152.png: 448x640 13 persons, 8 motorcycles, 448x640 12 persons, 9 motorcycles, 718.9ms\n",
      "Speed: 0.3ms pre-process, 359.5ms inference, 0.9ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp761\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets2.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets2.png: 480x640 3 persons, 3 bicycles, 3 cars, 1 backpack, 1 handbag, 480x640 3 persons, 3 bicycles, 4 cars, 1 backpack, 1 book, 812.7ms\n",
      "Speed: 0.4ms pre-process, 406.3ms inference, 1.2ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp762\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets754.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets754.png: 384x640 1 person, 2 cars, 384x640 1 person, 1 bicycle, 2 cars, 1 backpack, 543.7ms\n",
      "Speed: 0.5ms pre-process, 271.9ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp763\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets740.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets740.png: 352x640 12 persons, 9 bicycles, 1 backpack, 352x640 13 persons, 11 bicycles, 1 backpack, 467.6ms\n",
      "Speed: 0.3ms pre-process, 233.8ms inference, 0.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp764\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets595.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets595.png: 480x640 5 persons, 1 car, 1 motorcycle, 2 trucks, 480x640 5 persons, 1 car, 1 motorcycle, 1 truck, 692.0ms\n",
      "Speed: 0.5ms pre-process, 346.0ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp765\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets32.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets32.png: 640x480 2 persons, 2 bicycles, 640x480 2 persons, 2 bicycles, 3 backpacks, 633.7ms\n",
      "Speed: 0.4ms pre-process, 316.8ms inference, 0.9ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp766\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets581.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets581.png: 544x640 8 persons, 1 bicycle, 2 cars, 1 motorcycle, 1 truck, 1 backpack, 544x640 11 persons, 1 bicycle, 3 cars, 1 motorcycle, 1 backpack, 1 handbag, 779.3ms\n",
      "Speed: 0.5ms pre-process, 389.7ms inference, 1.0ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp767\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets26.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets26.png: 448x640 2 persons, 1 motorcycle, 448x640 2 persons, 1 motorcycle, 630.0ms\n",
      "Speed: 0.4ms pre-process, 315.0ms inference, 0.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp768\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets218.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets218.png: 640x640 2 persons, 1 bicycle, 640x640 2 persons, 1 bicycle, 826.7ms\n",
      "Speed: 0.5ms pre-process, 413.3ms inference, 0.9ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp769\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets556.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets556.png: 448x640 1 person, 1 bicycle, 3 cars, 1 motorcycle, 448x640 1 person, 1 bicycle, 3 cars, 2 motorcycles, 665.1ms\n",
      "Speed: 0.5ms pre-process, 332.5ms inference, 0.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp770\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets230.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets230.png: 352x640 2 persons, 1 bicycle, 1 motorcycle, 1 truck, 1 dog, 1 chair, 352x640 2 persons, 2 bicycles, 1 motorcycle, 1 truck, 518.2ms\n",
      "Speed: 0.3ms pre-process, 259.1ms inference, 0.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp771\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets224.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets224.png: 512x640 2 persons, 1 bicycle, 1 stop sign, 1 backpack, 1 handbag, 512x640 2 persons, 1 bicycle, 2 backpacks, 1 handbag, 689.7ms\n",
      "Speed: 0.5ms pre-process, 344.9ms inference, 1.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp772\u001b[0m\n",
      "/Users/mhnguyetvu/workspace/NLP-journey/Disaster-tweets/venv/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'], source=/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets542.png, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.9.6 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 839 layers, 68669632 parameters, 0 gradients, 241.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Flattening nested list structure. Original length: 2\n",
      "DEBUG: Flattened list length: 4\n",
      "WARNING: Skipping pred[2] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "WARNING: Skipping pred[3] due to conversion error: only one element tensors can be converted to Python scalars\n",
      "DEBUG: Model prediction type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images/BikesHelmets542.png: 384x640 1 person, 1 bicycle, 384x640 1 person, 1 bicycle, 468.3ms\n",
      "Speed: 0.6ms pre-process, 234.2ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9/runs/detect/exp773\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "\n",
    "def detect_helmet(image_path, weights_path):\n",
    "    \"\"\"Run YOLOv9 detection using detect.py script.\"\"\"\n",
    "    command = [\n",
    "        'python', '/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9/detect.py',\n",
    "        '--weights', weights_path,\n",
    "        '--source', image_path\n",
    "    ]\n",
    "    subprocess.run(command, check=True)\n",
    "\n",
    "def process_images(directory, weights_path):\n",
    "    \"\"\"Process all images in a given directory using detect.py.\"\"\"\n",
    "    image_files = [f for f in os.listdir(directory) if f.endswith(('png', 'jpg', 'jpeg'))]\n",
    "    for image_file in image_files:\n",
    "        image_path = os.path.join(directory, image_file)\n",
    "        detect_helmet(image_path, weights_path)\n",
    "\n",
    "# Set paths\n",
    "directory = '/Users/mhnguyetvu/workspace/helmet-detection-yolo/Helmet Detection Archive/images'\n",
    "weights_path = '/Users/mhnguyetvu/workspace/helmet-detection-yolo/yolov9/yolov9-e.pt'\n",
    "\n",
    "process_images(directory, weights_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of images: 764\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "764"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def count_images(directory):\n",
    "    \"\"\"Count the number of images in the given directory.\"\"\"\n",
    "    image_files = [f for f in os.listdir(directory) if f.endswith(('png', 'jpg', 'jpeg'))]\n",
    "    print(f\"Total number of images: {len(image_files)}\")\n",
    "    return len(image_files)\n",
    "\n",
    "# Count images in the directory\n",
    "count_images(directory)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
